{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "from tqdm.notebook import tqdm\n",
    "sns.set()\n",
    "rcParams['figure.figsize'] = (20,10)\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings('ignore')\n",
    "from pprint import pprint\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from googletrans import Translator\n",
    "import time\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, pipeline\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bigscience/bloom-3b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "def translate_df(df, batch_size=1, translator=translator):\n",
    "    def translate_text(text, sleep_time=2):\n",
    "        if text in [''] or text is None:\n",
    "            return ''\n",
    "        while True:\n",
    "            try:\n",
    "                return translator.translate(text, src=\"en\", dest=\"vi\").text\n",
    "            except:\n",
    "                print(\"Requests error\")\n",
    "                time.sleep(sleep_time)\n",
    "    \n",
    "    def clean_text(text):\n",
    "        return text\n",
    "    \n",
    "    data = defaultdict(list)\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_df = df.iloc[i : i + batch_size]\n",
    "        temp_data = defaultdict(list)\n",
    "        for col in df.columns:\n",
    "            batch_df[col] = batch_df[col].apply(lambda x: clean_text(x))\n",
    "            col_vals = ' ## '.join(batch_df[col].values)\n",
    "            temp_data[col] = [x.strip() for x in translate_text(col_vals).split('##')]\n",
    "\n",
    "        can_insert_batch = True\n",
    "        for col in df.columns:\n",
    "            if len(temp_data[col]) != len(batch_df):\n",
    "                can_insert_batch = False\n",
    "                break\n",
    "\n",
    "        if can_insert_batch:\n",
    "            for col in df.columns:\n",
    "                data[col].extend(batch_df[col].values)\n",
    "                data[f'{col}_translated'].extend(temp_data[col])\n",
    "            continue\n",
    "        \n",
    "        # else loop through each row\n",
    "        for _, row in batch_df.iterrows():\n",
    "            for col in df.columns:\n",
    "                text = clean_text(row[col])\n",
    "                data[col].append(text)\n",
    "                data[f'{col}_translated'].append(translate_text(text))\n",
    "                \n",
    "    df = pd.DataFrame(data)\n",
    "    return df.drop(columns=[col for col in df.columns if '_translated' not in col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"Cuộc trò chuyện giữa con người và trợ lý AI.\n",
    "[|Con người|] {prompt}\n",
    "[|AI|] {response}\n",
    "[|Con người|]\"\"\"\n",
    "\n",
    "def get_prompt(row):\n",
    "    return a.format(prompt=row['prompt'], response=row['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_json('../../data/translated/vi_alpaca_reduced.jsonl', lines=True)\n",
    "temp2 = temp.apply(lambda x: get_prompt(x), axis=1)\n",
    "temp2 = pd.DataFrame(temp2)\n",
    "temp2.columns = ['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = pd.read_json('../../data/translated/quora_chat_data_translated.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3.to_json('../../data/translated/quora_chat_data_translated.json',lines=True,orient='records')\n",
    "temp2.to_json('../../data/translated/alpaca_chat_cleaned_translated.json',lines=True,orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean ShareGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_gpt = pd.read_json('../../data/original/ShareGPT_V3_unfiltered_cleaned_split.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_programming_keywords = [\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"javascript\",\n",
    "    \"c#\",\n",
    "    \"c++\",\n",
    "    \"typescript\",\n",
    "    \"ruby\",\n",
    "    \"swift\",\n",
    "    \"kotlin\",\n",
    "    \"php\",\n",
    "    \"rust\",\n",
    "    \"scala\",\n",
    "    \"dart\",\n",
    "    \"matlab\",\n",
    "    \"objective-c\",\n",
    "    \"perl\",\n",
    "    \"lua\",\n",
    "    \"assert\",\n",
    "    \"async\",\n",
    "    \"await\",\n",
    "    \"def\",\n",
    "    \"elif\",\n",
    "    \"lambda\",\n",
    "    \"nonlocal\",\n",
    "    \"function\",\n",
    "    \"var\",\n",
    "    \"cuda\",\n",
    "    \"torch\",\n",
    "    \"code\",\n",
    "    \"sudo\",\n",
    "    \"bash\"\n",
    "]\n",
    "popular_programming_languages = [\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"javascript\",\n",
    "    \"typescript\",\n",
    "    \"kotlin\",\n",
    "    \"objective-c\",\n",
    "]\n",
    "def check_text_not_contain_code(text):\n",
    "    temp2 = text.lower()\n",
    "    temp = set(temp2.split())\n",
    "    for language in popular_programming_keywords:\n",
    "        if language in temp:\n",
    "            return False\n",
    "    for language in popular_programming_languages:\n",
    "        if language in temp2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "temp = share_gpt['conversations'].apply(lambda x: str(x)).apply(check_text_not_contain_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate of a Dataset\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "DataFrame().drop_duplicates(subset=['id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_gpt_no_code = share_gpt[temp][['conversations']]\n",
    "share_gpt_no_code = share_gpt_no_code[share_gpt_no_code['conversations'].apply(lambda x: len(x) >= 4)]\n",
    "share_gpt_no_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "\n",
    "\n",
    "def create_conversation(turns):\n",
    "    res = \"The conversation between human and AI assistant.\\n\"\n",
    "    for turn in turns:\n",
    "        if turn['from'] == 'human':\n",
    "            res += \"[|Human|] \" + turn['value'] + \"\\n\"\n",
    "        elif turn['from'] == 'gpt':\n",
    "            res += \"[|AI|] \" + turn['value'] + \"\\n\"\n",
    "        else:\n",
    "            return nan\n",
    "    return res\n",
    "\n",
    "share_gpt_no_code_conversations = share_gpt_no_code.apply(lambda x: create_conversation(x['conversations']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(share_gpt_no_code_conversations.sample(1).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_gpt_no_code_conversations.to_json('../../data/original/share_gpt_no_code_conversations.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_zero_shot_test = Dataset.from_json('../../../data/mmlu_eval_test/zero_shot_mmlu_test.json')\n",
    "mmlu_five_shot_test = Dataset.from_json('../../../data/mmlu_eval_test/five_shot_mmlu_test.json')\n",
    "mmlu_zero_shot_val = Dataset.from_json('../../../data/mmlu_eval_test/zero_shot_mmlu_val.json')\n",
    "mmlu_five_shot_val = Dataset.from_json('../../../data/mmlu_eval_test/five_shot_mmlu_val.json')\n",
    "\n",
    "def mapper(example):\n",
    "    text = 'The following are multiple choice questions (with answers) about'\n",
    "    example['input'] = example['input'].replace(f'{text} ', f'The conversation between human and AI assistant.\\n[|Human|] {text}')\n",
    "    example['output'] = f'[|AI|] {example[\"output\"]}\\n[|Human|]'\n",
    "    return example\n",
    "\n",
    "mmlu_zero_shot_test = mmlu_zero_shot_test.map(mapper)\n",
    "mmlu_zero_shot_val = mmlu_zero_shot_val.map(mapper)\n",
    "mmlu_five_shot_test = mmlu_five_shot_test.map(mapper)\n",
    "mmlu_five_shot_val = mmlu_five_shot_val.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mmlu_five_shot_test.shuffle()[0]\n",
    "print(temp['input'])\n",
    "print(temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mmlu_zero_shot_test.shuffle()[0]\n",
    "print(temp['input'])\n",
    "print(temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_zero_shot_test.to_json('../../../data/mmlu_eval_test/zero_shot_mmlu_chat_test.jsonl')\n",
    "mmlu_five_shot_test.to_json('../../../data/mmlu_eval_test/five_shot_mmlu_chat_test.jsonl')\n",
    "mmlu_zero_shot_val.to_json('../../../data/mmlu_eval_test/zero_shot_mmlu_chat_val.jsonl')\n",
    "mmlu_five_shot_val.to_json('../../../data/mmlu_eval_test/five_shot_mmlu_chat_val.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../data/translated/all_faqs.json'\n",
    "faqs = pd.read_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{instruction}\\n{input}\\nCâu trả lời: {output}\"\"\"\n",
    "print(template.format(**faqs.sample(1).iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = faqs['input'].apply(lambda x: not x.endswith('Điều luật liên quan: '))\n",
    "faqs = faqs[temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs['output_len'] = faqs['output'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs['output_len'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs_standard = faqs[faqs['output_len'] < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{instruction}\\n{input}\\nCâu trả lời: {output}\"\"\"\n",
    "print(template.format(**faqs_standard.sample(1).iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{instruction}\\n{input}\\nCâu trả lời: {output}\"\"\"\n",
    "print(template.format(**faqs.sample(1).iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/training/alpaca_chat_cleaned_51k_translated.json')\n",
    "temp.rename_column(temp.column_names[0], 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_json('../../data/original/gpt4-instruct-similarity-0.8-dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.shuffle()[0]['response'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "from glob import glob\n",
    "\n",
    "def load_dataset(folder_path, dataset_size=None):\n",
    "    data = []\n",
    "    file_paths = glob(folder_path + \"/*.jsonl\")\n",
    "    for path in file_paths:\n",
    "        ds = Dataset.from_json(path)\n",
    "        if len(ds.column_names) != 1:\n",
    "            raise ValueError(\"Dataset must have only one text column\")\n",
    "        ds = ds.rename_column(ds.column_names[0], \"text\")\n",
    "        data.append(ds)\n",
    "    if dataset_size is None:\n",
    "        return concatenate_datasets(data, axis=0).shuffle()\n",
    "    return concatenate_datasets(data, axis=0).shuffle().select(range(dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('../../data/training_31_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.shuffle()[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "def load_dataset(folder_path, dataset_size=None):\n",
    "    data = []\n",
    "    for path in glob(folder_path + \"/*.jsonl\"):\n",
    "        ds = Dataset.from_json(path)\n",
    "        if len(ds.column_names) != 1:\n",
    "            raise ValueError(\"Dataset must have only one text column\")\n",
    "        ds = ds.rename_column(ds.column_names[0], \"text\")\n",
    "        data.append(ds)\n",
    "    if dataset_size is None:\n",
    "        final_ds = concatenate_datasets(data, axis=0).shuffle(seed=42)\n",
    "    final_ds = (\n",
    "        concatenate_datasets(data, axis=0).shuffle(seed=42).select(range(dataset_size))\n",
    "    )\n",
    "    final_ds = final_ds.filter(lambda x: x[\"text\"] != \"\" or x[\"text\"] is not None)\n",
    "    return final_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('../../data/training_31_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x):\n",
    "    if x == '' or x is None:\n",
    "        return True\n",
    "    return False\n",
    "temp = df['text'].apply(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bigscience/bloomz-3b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tree = []\n",
    "with open('../../data/original/oasst_ready_trees.json') as f:\n",
    "    for line in f:\n",
    "        temp = json.loads(line)\n",
    "        if temp['prompt']['lang'] in ['en']:\n",
    "            en_tree.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_tree = []\n",
    "with open('../../data/original/oasst_ready_trees.json') as f:\n",
    "    for line in f:\n",
    "        temp = json.loads(line)\n",
    "        if temp['prompt']['lang'] in ['vi']:\n",
    "            vi_tree.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(root):\n",
    "    if len(root['replies']) == 0:\n",
    "        return [[(root['role'], root['text'])]]\n",
    "    data = []\n",
    "    for reply in root['replies']:\n",
    "        data.extend(traverse(reply))\n",
    "    data = [[(root['role'], root['text'])] + d for d in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_conversations = []\n",
    "for tree in en_tree:\n",
    "    en_conversations.extend(traverse(tree['prompt']))\n",
    "\n",
    "vi_conversations = []\n",
    "for tree in vi_tree:\n",
    "    vi_conversations.extend(traverse(tree['prompt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(en_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vi_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n{conversation}\"\n",
    "def format(conversations):\n",
    "    data = []\n",
    "    for conversation in conversations:\n",
    "        temp = \"\"\n",
    "        for turn in conversation:\n",
    "            if turn[0] == 'prompter':\n",
    "                temp += f\"[|Con người|] {turn[1]}\\n\"\n",
    "            else:\n",
    "                temp += f\"[|AI|] {turn[1]}\\n\"\n",
    "        data.append(templates.format(conversation=temp))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = format(en_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_data = format(vi_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(en_data[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.DataFrame(en_data, columns=['text'])\n",
    "en_df.to_json('../../data/original/en_oasst.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WiVi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wivi = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/wizard_vicuna_dataset_v2.json')\n",
    "def mapper(x):\n",
    "    conversation = \"\"\n",
    "    for turn in x['conversations']:\n",
    "        if turn['from'] == 'gpt':\n",
    "            conversation += f\"[|AI|] {turn['value']}\\n\" \n",
    "        elif turn['from'] == 'human':\n",
    "            conversation += f\"[|Human|] {turn['value']}\\n\"\n",
    "        else:\n",
    "            raise Exception()\n",
    "    x['conversations'] = conversation.strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "popular_programming_keywords = [\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"javascript\",\n",
    "    \"c#\",\n",
    "    \"c++\",\n",
    "    \"typescript\",\n",
    "    \"ruby\",\n",
    "    \"swift\",\n",
    "    \"kotlin\",\n",
    "    \"php\",\n",
    "    \"rust\",\n",
    "    \"scala\",\n",
    "    \"dart\",\n",
    "    \"matlab\",\n",
    "    \"objective-c\",\n",
    "    \"perl\",\n",
    "    \"elif\",\n",
    "    \"lambda\",\n",
    "    \"nonlocal\",\n",
    "    \"function\",\n",
    "    \"cuda\",\n",
    "    \"torch\",\n",
    "    \"code\",\n",
    "    \"sudo\",\n",
    "    \"bash\",\n",
    "    \"int\",\n",
    "    \"html\",\n",
    "    \"main()\",\n",
    "    \"chinese\",\n",
    "    '\\begin'\n",
    "]\n",
    "popular_programming_languages = [\n",
    "    \"sql\",\n",
    "    \"linux\",\n",
    "    \"</\",\n",
    "    \"/>\",\n",
    "    \"bash\",\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"javascript\",\n",
    "    \"typescript\",\n",
    "    \"swift\",\n",
    "    \"kotlin\",\n",
    "    \"rust\",\n",
    "    \"scala\",\n",
    "    \"dart\",\n",
    "    \"matlab\",\n",
    "    'latex',\n",
    "    '\\begin'\n",
    "]\n",
    "def check_text_not_contain_code(text):\n",
    "    temp2 = text.lower()\n",
    "    temp = set(temp2.split())\n",
    "    for language in popular_programming_keywords:\n",
    "        if language in temp:\n",
    "            return False\n",
    "    for language in popular_programming_languages:\n",
    "        if language in temp2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "wivi_no_code = wivi.map(mapper).filter(lambda x: check_text_not_contain_code(x['conversations']))\n",
    "wivi_no_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wivi_no_code.shuffle()[0]['conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wivi_no_code.to_json('../../../data/original/wizard_vicuna_nocode.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wizard = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/wizard_full.jsonl')\n",
    "def mapper(x):\n",
    "    conversation = \"\"\n",
    "    for turn in x['conversations']:\n",
    "        if turn['from'] == 'gpt':\n",
    "            conversation += f\"[|AI|] {turn['value']}\\n\" \n",
    "        elif turn['from'] == 'human':\n",
    "            conversation += f\"[|Human|] {turn['value']}\\n\"\n",
    "        else:\n",
    "            raise Exception()\n",
    "    x['conversations'] = conversation.strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "popular_programming_keywords = [\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"javascript\",\n",
    "    \"c#\",\n",
    "    \"c++\",\n",
    "    \"typescript\",\n",
    "    \"ruby\",\n",
    "    \"swift\",\n",
    "    \"kotlin\",\n",
    "    \"php\",\n",
    "    \"rust\",\n",
    "    \"scala\",\n",
    "    \"dart\",\n",
    "    \"matlab\",\n",
    "    \"objective-c\",\n",
    "    \"perl\",\n",
    "    \"elif\",\n",
    "    \"lambda\",\n",
    "    \"nonlocal\",\n",
    "    \"function\",\n",
    "    \"cuda\",\n",
    "    \"torch\",\n",
    "    \"code\",\n",
    "    \"sudo\",\n",
    "    \"bash\",\n",
    "    \"int\",\n",
    "    \"html\",\n",
    "    \"main()\",\n",
    "    \"chinese\",\n",
    "    '\\begin',\n",
    "]\n",
    "popular_programming_languages = [\n",
    "    \"sql\",\n",
    "    \"linux\",\n",
    "    \"</\",\n",
    "    \"/>\",\n",
    "    \"bash\",\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"javascript\",\n",
    "    \"c#\",\n",
    "    \"c++\",\n",
    "    \"typescript\",\n",
    "    \"swift\",\n",
    "    \"kotlin\",\n",
    "    \"rust\",\n",
    "    \"scala\",\n",
    "    \"dart\",\n",
    "    \"matlab\",\n",
    "    'latex'\n",
    "    '\\begin',\n",
    "]\n",
    "def check_text_not_contain_code(text):\n",
    "    temp2 = text.lower()\n",
    "    temp = set(temp2.split())\n",
    "    for language in popular_programming_keywords:\n",
    "        if language in temp:\n",
    "            return False\n",
    "    for language in popular_programming_languages:\n",
    "        if language in temp2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "wizard_no_code = wizard.map(mapper).filter(lambda x: check_text_not_contain_code(x['conversations']))\n",
    "wizard_no_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wizard_no_code.shuffle()[0]['conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/wizard_no_code.jsonl'\n",
    "wizard_no_code.to_json(path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\begin' in \"\"\"[|Human|] Can you provide a list of 3 popular tourist attractions in Tokyo? \n",
    "\\begin{itemize}\n",
    "    \\item The first tourist attraction is the Tokyo Tower, which is a communications and observation tower located in the Shiba-koen district of Minato, Tokyo. It stands at a height of 333 meters, making it one of the tallest structures in Japan.\n",
    "    \\item The second tourist attraction is the Sensoji Temple, which is a Buddhist temple located in the Asakusa district of Tokyo. It is one of the oldest and most famous temples in Tokyo, and it attracts millions of visitors every year.\n",
    "    \\item The third tourist attraction is the Meiji Shrine, which is a Shinto shrine located in the Shibuya district of Tokyo. It is dedicated to the deified spirits of Emperor Meiji and Empress Shoken, and it is one of the most popular shrines in Tokyo.\n",
    "\\end{itemize}\n",
    "[|AI|] These are the 3 popular tourist attractions in Tokyo:\n",
    "\\begin{enumerate}\n",
    "    \\item Tokyo Tower\n",
    "    \\item Sensoji Temple\n",
    "    \\item Meiji Shrine\n",
    "\\end{enumerate}\"\"\".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okapi_instruct = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/okapi/okapi_instruct_vi.json')\n",
    "okapi_rm = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/okapi/okapi_rm_vi.json')\n",
    "okapi_rl = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/okapi/okapi_rl_vi.json')\n",
    "okapi_rl = okapi_rl.rename_column('prefered_output','output')\n",
    "full_okapi =  concatenate_datasets([\n",
    "    okapi_instruct.select_columns(['instruction', 'input', 'output']),\n",
    "    okapi_rm.select_columns(['instruction', 'input', 'output']),\n",
    "    okapi_rl.select_columns(['instruction', 'input', 'output'])\n",
    "])\n",
    "full_okapi = Dataset.from_pandas(full_okapi.to_pandas().drop_duplicates(subset=['output']).reset_index(drop=True))\n",
    "print(okapi_instruct.shape, okapi_rm.shape, okapi_rl.shape, full_okapi.shape)\n",
    "full_okapi.shuffle()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\n",
    "    \"code\"\n",
    "    \"python\",\n",
    "    \"java\",\n",
    "    \"javascript\",\n",
    "    \"c#\",\n",
    "    \"c++\",\n",
    "    \"typescript\",\n",
    "    \"ruby\",\n",
    "    \"swift\",\n",
    "    \"kotlin\",\n",
    "    \"php\",\n",
    "    \"rust\",\n",
    "    \"scala\",\n",
    "    \"dart\",\n",
    "    \"matlab\",\n",
    "    \"objective-c\",\n",
    "    \"perl\",\n",
    "    \"elif\",\n",
    "    \"lambda\",\n",
    "    \"nonlocal\",\n",
    "    \"function\",\n",
    "    \"def\",\n",
    "    \"html\",\"css\",\n",
    "    \"sql\",\n",
    "    \"bash\",\n",
    "    'latex',\n",
    "    \"print\",\n",
    "    \"import\",\n",
    "    \"return\",\n",
    "    \"from\"\n",
    "]\n",
    "def check_text_contain_code(text):\n",
    "    if text is None or text == '':\n",
    "        return False\n",
    "    temp = text.lower()\n",
    "    for kw in key_words:\n",
    "        if kw in temp:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_code(x):\n",
    "    return check_text_contain_code(x['input']) or check_text_contain_code(x['output'])\n",
    "\n",
    "code_okapi = full_okapi.filter(filter_code)\n",
    "code_okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = code_okapi.shuffle()[0]\n",
    "print(temp['instruction'] + '\\n----\\n' + temp['input'] + '\\n----\\n' + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_code_okapi = full_okapi.filter(lambda x: not check_text_contain_code(x['input']) and not check_text_contain_code(x['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_code_okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = full_okapi.shuffle()[0]\n",
    "print(temp['instruction'] + '\\n----\\n' + temp['input'] + '\\n----\\n' + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_okapi.to_json('../../../data/original/okapi/full_okapi.jsonl', orient='records', lines=True)\n",
    "code_okapi.to_json('../../../data/original/okapi/code_related_okapi.jsonl', orient='records', lines=True)\n",
    "# no_code_okapi.to_json('../../../data/original/okapi/no_code_okapi.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
