{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set()\n",
    "rcParams['figure.figsize'] = (20,10)\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings('ignore')\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, pipeline\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/translated/mmlu/mmlu_all.json')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN_DAILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Dataset.from_json('../../data/translated/cnn_dailymail_30k_samples_len_100_1200_words_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template=\"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] Tóm tắt ngắn gọn đoạn văn bản sau đây:\\n{article_translated}\\n[|AI|] \"\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': input_template.format(article_translated=x['article_translated']),\n",
    "        'output': 'Đoạn văn bản đã được tóm tắt:\\n' + x['highlights_translated'] + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_cnn = cnn.shuffle().select(range(15000)).map(mapper,batched=False, remove_columns=['article_translated','highlights_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_cnn[1]['input'] + temp_cnn[1]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = temp_cnn.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['input'] + x['output']))})\n",
    "length.to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cnn.to_json('../../data/training_3_8/cnn_15k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIALOG SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = Dataset.from_json('../../data/translated/dialogsum_10k_samples_len_50_words_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template=\"Tóm tắt ngắn gọn đoạn hội thoại sau đây:\\n{dialogue_translated}\\nĐoạn hội thoại đã được tóm tắt:\\n\"\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': input_template.format(dialogue_translated=x['dialogue_translated']),\n",
    "        'output': x['summary_translated']\n",
    "    }\n",
    "\n",
    "temp_dialog = dialog.shuffle().select(range(10000)).map(mapper,batched=False, remove_columns=['dialogue_translated','summary_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_dialog[1]['input'] + temp_dialog[1]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dialog[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dialog.to_json('../../data/training_3_8/dialogsum_10k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = Dataset.from_json('../../data/training_31_7/faq_chat_10k.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = faqs.map(lambda x: {'length':len(tokenizer.tokenize(x['input']))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.length['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faqs.shuffle()[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "text2 = ' Nếu không đủ thông tin để trả lời thì trả lời: Tôi không biết.'\n",
    "text3 = 'Điều luật liên quan: '\n",
    "text4 = 'Chỉ được trả lời dựa trên điều luật được cung cấp'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['input'].removeprefix(text).replace(text2,'').replace(text3, 'Điều luật liên quan:\\n').replace(text4, 'Chỉ được trả lời dựa trên thông tin nằm trong điều luật được cung cấp') + '\\n[|Con người|]',\n",
    "    }\n",
    "\n",
    "temp_faqs = faqs.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_faqs.shuffle()[0]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs.to_json('../../data/training_3_8/faqs.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARE_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = pd.read_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/share_gpt_no_code_conversations_40k.json', orient='records', lines=True)\n",
    "share.columns = ['input']\n",
    "share.dropna(inplace=True)\n",
    "share.reset_index(drop=True, inplace=True)\n",
    "share = Dataset.from_pandas(share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = share.filter(lambda x: len(tokenizer.tokenize(x[\"input\"])) < 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['input']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "text = 'The conversation between human and AI assistant.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['input'].removeprefix(text) + '[|Human|]'\n",
    "    }\n",
    "share = share.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = share.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share.to_json('../../data/training_english/share_gpt_38k.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora = Dataset.from_json('../../data/translated/quora_chat_data_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quora.shuffle()[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['prompt']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_quora = quora.shuffle().select(range(20000))\n",
    "temp_quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['prompt'].removeprefix(text) + '\\n[|Con người|]',\n",
    "    }\n",
    "\n",
    "temp_quora = temp_quora.map(mapper, batched=False, remove_columns=['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_quora.to_json('../../data/training_3_8/quora_20k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OASST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_oasst = Dataset.from_json('../../data/translated/en_oasst_translated.json')\n",
    "# en_oasst = en_oasst.rename_column('text_translated','text')\n",
    "# vi_oasst = Dataset.from_json('../../data/original/oasst/vi_oasst.json')\n",
    "\n",
    "ds = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/oasst/en_oasst.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "text = 'The conversation between human and AI assistant.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['text'].removeprefix(text),\n",
    "    }\n",
    "\n",
    "temp_oasst = ds.map(mapper, batched=False, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_oasst.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst.to_json('../../data/training_3_8/oasst_21k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasst.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['text']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_oasst.shuffle()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst.to_json('../../data/training_english/oasst_20k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALPACA CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = Dataset.from_json('../../data/training_31_7/alpaca_chat_15k.jsonl')\n",
    "alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['input'].removeprefix(text)\n",
    "    }\n",
    "temp_alpaca = alpaca.map(mapper, batched=False, remove_columns=['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_alpaca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_alpaca.to_json('../../data/training_3_8/alpaca_chat_15k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 INSTRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/gpt4_instruct_similarity_0_9.json')\n",
    "gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"[|Human|] {instruction}\\n{input}\\n[|AI|] \"\n",
    "template2 = \"[|Human|] {instruction}\\n[|AI|] \"\n",
    "\n",
    "def mapper(x):\n",
    "    if x['input'] != '' and x['input'] is not None:\n",
    "        template = template1.format(\n",
    "            instruction=x['instruction'], \n",
    "            input=x['input']\n",
    "        )\n",
    "    else:\n",
    "        template = template2.format(instruction=x['instruction'])\n",
    "    return {\n",
    "        'input': template,\n",
    "        'output': x['response']\n",
    "    }\n",
    "\n",
    "temp_gpt4 = gpt4.map(mapper,batched=False, remove_columns=gpt4.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = temp_gpt4.shuffle()[0]\n",
    "print(a['input']+a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gpt4.to_json('../../data/training_english/gpt4_instruct.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOLLY WITH CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/dolly_with_context.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly.shuffle()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template1 = \"The conversation between human and AI assistant.\\n[|Human|] Trả lời câu hỏi dựa vào đoạn văn bản dưới đây. Chỉ được trả lời dựa trên thông tin nằm trong văn bản được cung cấp.\\nCâu hỏi: {instruction}\\nĐoạn văn bản:\\n{context}\\n[|AI|] \"\n",
    "template1 = \"[|Human|] Answer the question given the following context.\\nQuestion: {instruction}\\Context:\\n{context}\\n[|AI|] \"\n",
    "\n",
    "def mapper(x):\n",
    "    ip = template1.format(\n",
    "        instruction=x['instruction'], \n",
    "        context=x['context']\n",
    "    )\n",
    "    return {\n",
    "        'input': ip,\n",
    "        'output': x['response']\n",
    "    }\n",
    "\n",
    "temp_dolly = dolly.map(mapper,batched=False, remove_columns=dolly.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp_dolly.to_pandas()\n",
    "df = df.sample(8000, random_state=42, replace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "temp_dolly = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_dolly.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuộc trò chuyện giữa con người và trợ lý AI.\n",
    "[|Con người|] Trả lời câu hỏi pháp luật dựa vào những điều luật liên quan dưới đây. Chỉ được trả lời dựa trên thông tin nằm trong điều luật được cung cấp.\n",
    "Câu hỏi: Phạm tội trong trạng thái tinh thần bị kích động mạnh bị xử lý thế nào?\n",
    "Điều luật liên quan:\n",
    "Điều 125. Tội giết người trong trạng thái tinh thần bị kích động mạnh 1. Người nào giết người trong trạng thái tinh thần bị kích động mạnh do hành vi trái pháp luật nghiêm trọng của nạn nhân đối với người đó hoặc đối với người thân thích của người đó, thì bị phạt tù từ 06 tháng đến 03 năm. 2. Phạm tội đối với 02 người trở lên, thì bị phạt tù từ 03 năm đến 07 năm.\n",
    "[|AI|] Giết người trong trạng thái tinh thần bị kích động mạnh Tội giết người trong trạng thái tinh thần bị kích động mạnh được quy định tại Điều 125 Bộ luật Hình sự 2015 sửa đổi, bổ sung 2017 với mức hình phạt như sau: Khung 1: Người nào giết người trong trạng thái tinh thần bị kích động mạnh do hành vi trái pháp luật nghiêm trọng của nạn nhân đối với người đó hoặc đối với người thân thích của người đó, thì bị phạt tù từ 06 tháng đến 03 năm. Khung 2: Phạm tội đối với 02 người trở lên, thì bị phạt tù từ 03 năm đến 07 năm.\n",
    "[|Con người|]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dolly.to_json('../../data/training_english/dolly_4k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "def load_dataset(folder_path, dataset_size=None):\n",
    "    data = []\n",
    "    for path in glob(folder_path + \"/*.jsonl\"):\n",
    "        ds = Dataset.from_json(path)\n",
    "        for check in ['input', 'output']:\n",
    "            if check not in ds.column_names:\n",
    "                raise ValueError(\"Dataset must have input, output columns\")\n",
    "        # take only the input and output columns\n",
    "        ds = ds.select_columns(['input', 'output'])\n",
    "        data.append(ds)\n",
    "    if dataset_size is None:\n",
    "        return concatenate_datasets(data, axis=0).shuffle(seed=42)\n",
    "    return (\n",
    "        concatenate_datasets(data, axis=0).shuffle(seed=42).select(range(dataset_size))\n",
    "    )\n",
    "\n",
    "def clean(ds):\n",
    "    def mapper(x):\n",
    "        for column in ds.column_names:\n",
    "            x[column] = x[column].replace('[|Human|]','[|Con người|]').replace('\\n[|Con người|]\\n[|Con người|]', '\\n[|Con người|]')\n",
    "        return x\n",
    "    def filter(x):\n",
    "        for column in ds.column_names:\n",
    "            if x[column] == '' or x[column] is None:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    new_ds = ds.map(mapper,batched=False)\n",
    "    new_ds = new_ds.filter(filter)\n",
    "    return new_ds        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('../../data/training_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ds.shuffle()[0]\n",
    "print(a['input'])\n",
    "print(a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = '../../data/english_training/all_11_8.jsonl'\n",
    "ds.to_json(path_to_save, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['input']+x['output']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_length = df.apply(lambda x: len(tokenizer.tokenize(x['input']+x['output'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df_length <= 512].reset_index(drop=True)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = temp_df.sample(60000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_json('../../data/temp_training/final_dataset.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/formatted_toolformer-similarity-0.8-dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shuffle()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wizard = load_dataset('WizardLM/WizardLM_evol_instruct_V2_196k')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wizard.to_json('../../../data/original/wizard_full.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
