{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set()\n",
    "rcParams['figure.figsize'] = (20,10)\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings('ignore')\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, pipeline\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-7b1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-324e22197086a422/0.0.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ed3d18614f4b29b5a6c9688a25788e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = Dataset.from_json('./temp.jsonl')\n",
    "temp = temp.filter(lambda x: x['pred'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ai là người có quyền lực cao nhất Paris thời gian sau khi bỏ chế độ phong kiến?\n",
      "['nhà thiên văn Jean Sylvain Bailly', 'Quốc hội', 'Quốc hội', 'Quốc hội']\n",
      "Thị trưởng Jacques de Flesselles\n",
      "Nhà thiên văn Jean Sylvain Bailly\n",
      "Thị trưởng đầu tiên của Paris\n",
      "Tuileries\n",
      "Quốc hội lập hiến\n",
      "Tuileries\n"
     ]
    }
   ],
   "source": [
    "a = temp.shuffle()[0]\n",
    "print(a['question'])\n",
    "print(a['answer'])\n",
    "print(a['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN_DAILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Dataset.from_json('../../data/translated/cnn_dailymail_30k_samples_len_100_1200_words_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template=\"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] Tóm tắt ngắn gọn đoạn văn bản sau đây:\\n{article_translated}\\n[|AI|] \"\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': input_template.format(article_translated=x['article_translated']),\n",
    "        'output': 'Đoạn văn bản đã được tóm tắt:\\n' + x['highlights_translated'] + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_cnn = cnn.shuffle().select(range(15000)).map(mapper,batched=False, remove_columns=['article_translated','highlights_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_cnn[1]['input'] + temp_cnn[1]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = temp_cnn.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['input'] + x['output']))})\n",
    "length.to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cnn.to_json('../../data/training_3_8/cnn_15k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIALOG SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = Dataset.from_json('../../data/translated/dialogsum_10k_samples_len_50_words_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template=\"Tóm tắt ngắn gọn đoạn hội thoại sau đây:\\n{dialogue_translated}\\nĐoạn hội thoại đã được tóm tắt:\\n\"\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': input_template.format(dialogue_translated=x['dialogue_translated']),\n",
    "        'output': x['summary_translated']\n",
    "    }\n",
    "\n",
    "temp_dialog = dialog.shuffle().select(range(10000)).map(mapper,batched=False, remove_columns=['dialogue_translated','summary_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_dialog[1]['input'] + temp_dialog[1]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dialog[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dialog.to_json('../../data/training_3_8/dialogsum_10k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "faqs = Dataset.from_json('../../../data/training_31_7/faq_chat_10k.jsonl')\n",
    "print(faqs.shuffle()[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "text2 = ' Nếu không đủ thông tin để trả lời thì trả lời: Tôi không biết.'\n",
    "text3 = 'Điều luật liên quan: '\n",
    "text4 = ' Chỉ được trả lời dựa trên điều luật được cung cấp.'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['input'].removeprefix(text).replace(text2,'').replace(text3, 'Điều luật liên quan:\\n').replace(text4, '') + '\\n[|Con người|]',\n",
    "    }\n",
    "\n",
    "def mapper2(x):\n",
    "    ai_index = x['output'].find('[|AI|]')\n",
    "    return {\n",
    "        'input': x['input'] + x['output'][:ai_index + 7],\n",
    "        'output': x['output'][ai_index + 7:],\n",
    "    }\n",
    "\n",
    "temp_faqs = faqs.map(mapper, batched=False).map(mapper2, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs_df = temp_faqs.to_pandas()\n",
    "temp_faqs_df = temp_faqs_df.drop_duplicates(subset=['output']).reset_index(drop=True)\n",
    "temp_faqs_df['length_input'] = temp_faqs_df['input'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "temp_faqs_df['length_output'] = temp_faqs_df['output'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "temp_faqs_df['similarity'] = temp_faqs_df.apply(lambda x: fuzz.ratio(x['input'], x['output']) / (x['length_input'] + x['length_output']), axis=1)\n",
    "temp_faqs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs_df['length_input'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs_df['length_output'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs_df['similarity'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1 = temp_faqs_df[(temp_faqs_df['length_output'] <= 0.6 * temp_faqs_df['length_input']) & (temp_faqs_df['length_output'] <= 300) & (temp_faqs_df['similarity'] <= 0.07)].reset_index(drop=True)\n",
    "temp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs = Dataset.from_pandas(temp_1)\n",
    "temp = temp_faqs.shuffle()[0]\n",
    "print(temp['input'])\n",
    "print(temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "text = 'Trả lời câu hỏi pháp luật dựa vào những điều luật liên quan dưới đây.'\n",
    "instruction_templates = {\n",
    "    0: text,\n",
    "    1: 'Giúp tôi trả lời câu hỏi pháp luật dựa vào những điều luật dưới đây.',\n",
    "    2: 'Trả lời câu hỏi pháp luật sau đây.',\n",
    "    3: 'Dựa vào những điều luật được cung cấp, hãy trả lời câu hỏi pháp luật sau đây.',\n",
    "    4: 'Sau đây là những điều luật liên quan đến câu hỏi pháp luật. Hãy trả lời câu hỏi pháp luật sau đây.',\n",
    "}\n",
    "\n",
    "question_templates = {\n",
    "    0: 'Câu hỏi pháp luật: ',\n",
    "    1: 'Câu hỏi: ',\n",
    "    2: '',\n",
    "}\n",
    "\n",
    "cite_templates = {\n",
    "    0: 'Điều luật liên quan:',\n",
    "    1: 'Điều luật:',\n",
    "}\n",
    "def mapper(x):\n",
    "    a = choice([0,0,0,1,2,3,4])\n",
    "    b = choice([0,0,0,1,1,1,2])\n",
    "    c = choice([0,1])\n",
    "    return {\n",
    "        'input': x['input'].replace(text, instruction_templates[a]).replace('Câu hỏi: ', question_templates[b]).replace('Điều luật liên quan:', cite_templates[c]),\n",
    "        'output': x['output']\n",
    "    }\n",
    "\n",
    "temp_faqs = temp_faqs.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_faqs.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs.remove_columns(['length_input', 'length_output'])\n",
    "temp_faqs.to_json('../../../data/training_21_8/faqs_400_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARE_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = pd.read_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/share_gpt_no_code_conversations_40k.json', orient='records', lines=True)\n",
    "share.columns = ['input']\n",
    "share.dropna(inplace=True)\n",
    "share.reset_index(drop=True, inplace=True)\n",
    "share = Dataset.from_pandas(share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = share.filter(lambda x: len(tokenizer.tokenize(x[\"input\"])) < 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['input']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "text = 'The conversation between human and AI assistant.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['input'].removeprefix(text) + '\\n[|Con người|]'\n",
    "    }\n",
    "share = share.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share.to_json('../../data/training_english/share_gpt_38k.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora = Dataset.from_json('../../../data/translated/quora_chat_data_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quora.shuffle()[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['prompt']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_quora = quora.shuffle().select(range(20000))\n",
    "temp_quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['prompt'].removeprefix(text)\n",
    "    }\n",
    "\n",
    "temp_quora = temp_quora.map(mapper, batched=False, remove_columns=['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_quora.shuffle()[0]\n",
    "print(temp['input'])\n",
    "print(temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_quora.shuffle().select(range(5000)).to_json('../../../data/training_21_8/quora_5k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasst = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/translated/oasst_translated.json')\n",
    "oasst = oasst.filter(lambda x: not ('```' in x['text'] or 'trăn' in x['text'] or \"'''\" in x['text']))\n",
    "oasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst2 = oasst.filter(lambda x: len(tokenizer.tokenize(x['text'])) > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['text'].removeprefix(text)\n",
    "    }\n",
    "\n",
    "temp_oasst = temp_oasst2.map(mapper, batched=False, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_oasst.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst.shuffle().select(range(5000)).to_json('../../../data/training_21_8/oasst_5k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasst.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['text']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_oasst.shuffle()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst.to_json('../../data/training_3_8/oasst_20k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALPACA CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = Dataset.from_json('../../../data/translated/alpaca_chat_cleaned_51k_translated.json')\n",
    "temp_df = alpaca.to_pandas()\n",
    "temp_length = temp_df.apply(lambda x: len(tokenizer.tokenize(x['prompt'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_temp = Dataset.from_pandas(temp_df[temp_length>=150].reset_index(drop=True))\n",
    "alpaca_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alpaca_temp.shuffle()[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(x):\n",
    "    ai_index = x['prompt'].find('[|AI|]')\n",
    "    return {\n",
    "        'input': x['prompt'][:ai_index+7],\n",
    "        'output': x['prompt'][ai_index + 7:]\n",
    "    }\n",
    "temp_alpaca = alpaca_temp.map(mapper, batched=False, remove_columns=alpaca.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_alpaca.shuffle()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_alpaca.to_json('../../../data/training_14_8/alpaca_chat_26k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 INSTRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = Dataset.from_json('../../../data/translated/gpt4_instruct_similarity_0_9_translated.jsonl')\n",
    "gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] {instruction_translated}\\n{input_translated}\\n[|AI|] \"\n",
    "template2 = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] {instruction_translated}\\n[|AI|] \"\n",
    "\n",
    "def mapper(x):\n",
    "    if x['input_translated'] != '' and x['input_translated'] is not None:\n",
    "        template = template1.format(\n",
    "            instruction_translated=x['instruction_translated'], \n",
    "            input_translated=x['input_translated']\n",
    "        )\n",
    "    else:\n",
    "        template = template2.format(instruction_translated=x['instruction_translated'])\n",
    "    return {\n",
    "        'input': template,\n",
    "        'output': x['response_translated'] + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_gpt4 = gpt4.map(mapper,batched=False, remove_columns=gpt4.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_gpt4.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = temp_gpt4.shuffle()[0]\n",
    "print(a['input']+a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gpt4.to_json('../../data/training_3_8/gpt4_instruct.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOLLY WITH CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly = Dataset.from_json('../../../data/translated/dolly_with_context_translated.jsonl')\n",
    "# dolly = dolly.remove_columns(['instruction', 'context', 'response', 'category_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dolly.shuffle()[0]\n",
    "print(temp['context_translated'])\n",
    "print('----------')\n",
    "print(temp['instruction_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly.shuffle()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "pretext = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] '\n",
    "instruction_templates = [\n",
    "    \"Trả lời câu hỏi dựa vào đoạn văn bản dưới đây. Nếu không có thông tin trong đoạn văn bản thì trả lời: Tôi không biết.\\nCâu hỏi: {instruction_translated}\\nĐoạn văn bản:\\n{context_translated}\\n[|AI|] \",\n",
    "    \"Giúp tôi trả lời câu hỏi sau đây.\\nCâu hỏi: {instruction_translated}\\nĐoạn văn bản:\\n{context_translated}\\n[|AI|] \",\n",
    "    \"Sử dụng thông tin trong văn bản sau đây để trả lời câu hỏi.\\nVăn bản:\\n{context_translated}\\nCâu hỏi: {instruction_translated}\\n[|AI|] \",\n",
    "    \"Hãy trả lời câu hỏi sau sử dụng thông tin của đoạn văn bản được cung cấp, nếu không có thông tin thì phản hồi không trả lời được.\\n{context_translated}\\nCâu hỏi: {instruction_translated}\\n[|AI|] \",\n",
    "    \"Trả lời câu hỏi sử dụng đoạn văn bản sau.\\n{context_translated}\\n{instruction_translated}\\n[|AI|] \",\n",
    "    \"Đưa ra phản hồi cho câu hỏi sau đây, nếu không tìm thấy thông tin thì trả lời: Không có thông tin cho câu hỏi của bạn.\\n{context_translated}\\nCâu hỏi: {instruction_translated}\\n[|AI|] \",\n",
    "]\n",
    "\n",
    "def mapper(x):\n",
    "    ip = pretext + choice(instruction_templates).format(\n",
    "        instruction_translated=x['instruction_translated'],\n",
    "        context_translated=x['context_translated']\n",
    "    )\n",
    "    return {\n",
    "        'input': ip,\n",
    "        'output': choice([''] * 9 + ['Trả lời: ', 'Câu trả lời: ']) + x['response_translated'] + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_dolly = dolly.map(mapper,batched=False, remove_columns=dolly.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_dolly.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuộc trò chuyện giữa con người và trợ lý AI.\n",
    "[|Con người|] Trả lời câu hỏi pháp luật dựa vào những điều luật liên quan dưới đây. Chỉ được trả lời dựa trên thông tin nằm trong điều luật được cung cấp.\n",
    "Câu hỏi: Phạm tội trong trạng thái tinh thần bị kích động mạnh bị xử lý thế nào?\n",
    "Điều luật liên quan:\n",
    "Điều 125. Tội giết người trong trạng thái tinh thần bị kích động mạnh 1. Người nào giết người trong trạng thái tinh thần bị kích động mạnh do hành vi trái pháp luật nghiêm trọng của nạn nhân đối với người đó hoặc đối với người thân thích của người đó, thì bị phạt tù từ 06 tháng đến 03 năm. 2. Phạm tội đối với 02 người trở lên, thì bị phạt tù từ 03 năm đến 07 năm.\n",
    "[|AI|] Giết người trong trạng thái tinh thần bị kích động mạnh Tội giết người trong trạng thái tinh thần bị kích động mạnh được quy định tại Điều 125 Bộ luật Hình sự 2015 sửa đổi, bổ sung 2017 với mức hình phạt như sau: Khung 1: Người nào giết người trong trạng thái tinh thần bị kích động mạnh do hành vi trái pháp luật nghiêm trọng của nạn nhân đối với người đó hoặc đối với người thân thích của người đó, thì bị phạt tù từ 06 tháng đến 03 năm. Khung 2: Phạm tội đối với 02 người trở lên, thì bị phạt tù từ 03 năm đến 07 năm.\n",
    "[|Con người|]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_pandas(temp_dolly.to_pandas().sample(5000, replace=True).reset_index(drop=True)).to_json('../../../data/training_21_8/dolly_4k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = Dataset.from_json('../../../data/translated/roleplay_translated.jsonl')\n",
    "role = Dataset.from_pandas(role.data.to_pandas().sample(5000, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] {instruction_translated}\\n[|AI|] \"\n",
    "template2 = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] {instruction_translated}\\n{input_translated}\\n[|AI|] \"\n",
    "\n",
    "def mapper(x):\n",
    "    if x['input_translated'] == '':\n",
    "        ip = template1.format(\n",
    "            instruction_translated=x['instruction_translated'], \n",
    "        )\n",
    "    else:\n",
    "        ip = template2.format(\n",
    "            instruction_translated=x['instruction_translated'], \n",
    "            input_translated=x['input_translated']\n",
    "        )\n",
    "    return {\n",
    "        'input': ip,\n",
    "        'output': x['output_translated'] + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_role = role.map(mapper,batched=False, remove_columns=role.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_role.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_role.to_json('../../../data/training_14_8/role_play_3k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orca = Dataset.from_json('../../../data/translated/orca_translated_50k.jsonl')\n",
    "orca = orca.remove_columns(['system_prompt','question','response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = orca.shuffle()[0]\n",
    "print(temp['system_prompt_translated'])\n",
    "print('------------------')\n",
    "print(temp['question_translated'])\n",
    "print('------------------')\n",
    "print(temp['response_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"{system_prompt}\\n[|Con người|] {question}\\n[|AI|] \"\n",
    "template2 = \"[|Con người|] {question}\\n[|AI|] \"\n",
    "\n",
    "def mapper(x):\n",
    "    if x['system_prompt_translated'] == '':\n",
    "        ip = template2.format(\n",
    "            question=x['question_translated'],\n",
    "        )\n",
    "    else:\n",
    "        ip = template1.format(\n",
    "            system_prompt=x['system_prompt_translated'],\n",
    "            question=x['question_translated'],\n",
    "        )\n",
    "    return {\n",
    "        'input': ip,\n",
    "        'output': x['response_translated'] + '\\n[|Con người|]',\n",
    "    }\n",
    "\n",
    "temp_orca = orca.map(mapper, remove_columns=orca.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_orca.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_orca.shuffle().select(range(25000)).to_json('../../../data/training_21_8/orca_25k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wivi = Dataset.from_json('../../../data/translated/wizard_vicuna_nocode_translated.jsonl')\n",
    "wivi = wivi.select_columns(['conversations_translated'])\n",
    "wivi = wivi.rename_column('conversations_translated', 'conversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wivi[0]['conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n\"\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['conversation'].removeprefix(text) + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_wivi = wivi.map(mapper, batched=False, remove_columns=wivi.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_wivi.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_wivi.to_json('../../../data/training_21_8/wivi_30k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation query generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-3ecfe4735495290c/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-0bad7c81935852e3/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-63a04f4664c48905/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "data_path = [\n",
    "    \"../../../data/translated/retrieve_query_gen_oasst_translated.jsonl\", \n",
    "    \"../../../data/translated/retrieve_query_gen_quora_translated.jsonl\", \n",
    "    \"../../../data/translated/retrieve_query_gen_sharegpt_translated.jsonl\",\n",
    "]\n",
    "query = concatenate_datasets([Dataset.from_json(path) for path in data_path])\n",
    "temp = query.to_pandas().drop_duplicates(subset=['conversation']).sample(500, replace=True)\n",
    "query = Dataset.from_pandas(temp.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation', 'conversation_translated', 'query', 'query_translated'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(\"Hello from hoang\").find(\"hoang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1e1f28dbd04558ab241480dd7bc816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template1 = \"Dưới đây là đoạn hội thoại giữa con người và AI, cuối đoạn hội thoại là câu hỏi mới người dùng đặt ra cần được trả lời bằng cách tìm kiếm thông tin nằm trong cơ sở tri thức chung. Hãy sinh ra câu truy vấn phù hợp với đoạn hội thoại và câu hỏi mới của người dùng.\\nĐoạn hội thoại:\\n{conversation}\\nCâu truy vấn: \"\n",
    "\n",
    "def mapper(x):\n",
    "    ip = template1.format(\n",
    "        conversation=x['conversation_translated'], \n",
    "    )\n",
    "    return {\n",
    "        'input': ip,\n",
    "        'output': x['query_translated']\n",
    "    }\n",
    "\n",
    "temp_query = query.map(mapper,batched=False, remove_columns=query.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dưới đây là đoạn hội thoại giữa con người và AI, cuối đoạn hội thoại là câu hỏi mới người dùng đặt ra cần được trả lời bằng cách tìm kiếm thông tin nằm trong cơ sở tri thức chung. Hãy sinh ra câu truy vấn phù hợp với đoạn hội thoại và câu hỏi mới của người dùng.\n",
      "Đoạn hội thoại:\n",
      "[|Con người|] Hãy giải thích cho tôi giống như tôi 7 tuổi, trí tuệ nhân tạo là gì.\n",
      "[|AI|] Chắc chắn rồi, tôi có thể giải thích cho bạn theo cách mà bạn có thể hiểu được!\n",
      "\n",
      "Trí tuệ nhân tạo (AI) là một chương trình máy tính hoặc máy móc có thể làm những việc mà thông thường đòi hỏi trí thông minh của con người phải làm. Nó có thể học hỏi kinh nghiệm và cải thiện theo thời gian, giống như cách bạn trở nên giỏi hơn trong một trò chơi khi bạn chơi nó nhiều hơn.\n",
      "\n",
      "Ví dụ, bạn đã bao giờ chơi một trò chơi mà máy tính là đối thủ của bạn chưa? Máy tính đưa ra quyết định và chơi trò chơi giống như người thật, nhưng thực tế nó chỉ là một chương trình được thiết kế để làm điều đó. Đó là một ví dụ về AI!\n",
      "\n",
      "AI được sử dụng trong nhiều thứ như trợ lý giọng nói (như Siri và Alexa), ô tô tự lái và thậm chí cả trong rô-bốt có thể làm những việc như hút bụi sàn nhà hoặc chơi trò chơi với bạn.\n",
      "[|Con người|] Chà, thật tuyệt! Vậy AI giống như có một người bạn robot thông minh, có thể học và làm những việc như con người?\n",
      "Câu truy vấn: trí tuệ nhân tạo dùng để làm gì\n"
     ]
    }
   ],
   "source": [
    "temp = temp_query.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_query.to_json('../../../data/training_14_8/query_gen_500_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wizard = Dataset.from_json('../../../data/translated/wizard_no_code_translated.jsonl')\n",
    "wizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = wizard.shuffle()[0]\n",
    "print(temp['conversations_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n\"\n",
    "def mapper(x):\n",
    "    index = x['conversations_translated'].find('[|AI|]')\n",
    "    return {\n",
    "        'input': text + x['conversations_translated'][:index+7],\n",
    "        'output': x['conversations_translated'][index+7:] + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_wizard = wizard.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_wizard.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_wizard.shuffle().select(range(40000)).to_json('../../../data/training_21_8/wizard_30k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ocapi = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/okapi/code_related_okapi.jsonl')\n",
    "no_code_ocapi = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/okapi/okapi_instruct_vi.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] {instruction}\\n{input}\\n[|AI|] \"\n",
    "template2 = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] {instruction}\\n[|AI|] \"\n",
    "\n",
    "def mapper(x):\n",
    "    if x['input'] == '':\n",
    "        ip = template2.format(\n",
    "            instruction=x['instruction'],\n",
    "        )\n",
    "    else:\n",
    "        ip = template1.format(\n",
    "            instruction=x['instruction'],\n",
    "            input=x['input']\n",
    "        )\n",
    "    return {\n",
    "        'input': ip,\n",
    "        'output': x['output'] + '\\n[|Con người|]'\n",
    "    }\n",
    "\n",
    "temp_code_ocapi = code_ocapi.map(mapper, remove_columns=code_ocapi.column_names)    \n",
    "temp_no_code_ocapi = no_code_ocapi.map(mapper, remove_columns=no_code_ocapi.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_code_ocapi.to_json('../../../data/training_21_8/code_related_ocapi_6k_samples.jsonl', orient='records', lines=True)\n",
    "temp_no_code_ocapi.shuffle().select(range(30000)).to_json('../../../data/training_21_8/no_code_ocapi_30k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_no_code_ocapi.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_test = Dataset.from_json('../../../data/translated/mmlu/zero_shot_mmlu_chat_test_translated.jsonl')\n",
    "mmlu_val = Dataset.from_json('../../../data/translated/mmlu/zero_shot_mmlu_chat_val_translated.jsonl')\n",
    "print(len(mmlu_test), len(mmlu_val))\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': x['input_translated'] + \"\\n[|AI|] \",\n",
    "        'output': x['output_translated'].removeprefix(\"[|AI|] \").replace(\"[|Human|]\", \"[|Con người|]\")\n",
    "    }\n",
    "def filter(x):\n",
    "    for a in ['A.', 'B.', 'C.', 'D.']:\n",
    "        if not a in x['input']:\n",
    "            return False\n",
    "    for a in ['A\\n[|Con người|]', 'B\\n[|Con người|]', 'C\\n[|Con người|]', 'D\\n[|Con người|]']:\n",
    "        if a in x['output']:\n",
    "            return True\n",
    "mmlu_val = mmlu_val.map(mapper).filter(filter)\n",
    "mmlu_test = mmlu_test.map(mapper).filter(filter)\n",
    "print(len(mmlu_test), len(mmlu_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mmlu_test.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_val.to_json('../../../data/training_21_8/eval_test/mmlu_zeroshot_val.jsonl', orient='records', lines=True)\n",
    "mmlu_test.to_json('../../../data/training_21_8/eval_test/mmlu_zeroshot_test.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad V2 (No answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "squadv2 = Dataset.from_json('../../../data/translated/squad2_no_ans_translated.jsonl').shuffle().select(range(1500))\n",
    "\n",
    "\n",
    "pre_text = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] \"\n",
    "\n",
    "prompts1 = [\n",
    "    'Hãy trả lời câu hỏi sau\\n{question}\\nThông tin:\\n{context}',\n",
    "    'Phản hồi lại câu hỏi sau đây sử dụng thông tin trong đoạn văn bản.\\nVăn bản:\\n{context}\\nCâu hỏi: {question}',\n",
    "    \"{context}\\nCâu hỏi: {question}\",\n",
    "    'Trả lời câu hỏi dựa vào đoạn văn bản sau đây.\\nĐoạn văn bản:\\n{context}\\nCâu hỏi:\\n{question}',\n",
    "    'Trả lời câu hỏi sau đây, chỉ sử dụng thông tin nằm trong đoạn văn bản.\\nĐoạn văn bản:\\n{context}\\n{question}',\n",
    "    'Sử dụng thông tin trong đoạn trích để trả lời câu hỏi sau:\\n{question}\\nĐoạn trích:\\n{context}',\n",
    "]\n",
    "\n",
    "prompts2 = [\n",
    "    [\"Trả lời câu hỏi dựa vào thông tin trong đoạn văn bản sau đây. Nếu không tìm thấy thống tin nằm trong đoạn văn bản thì trả lời: Không có thông tin cho câu hỏi của bạn.\\n{context}\\nCâu hỏi: {question}\\n[|AI|] \", \"Không có thông tin cho câu hỏi của bạn.\\n[|Con người|]\"],\n",
    "    [\"Sử dụng thông tin trong đoạn văn bản sau đây để trả lời câu hỏi. Nếu không tìm thấy thống tin nằm trong đoạn văn bản thì trả lời: Không có thông tin cho câu hỏi của bạn.\\nCâu hỏi: {question}\\nĐoạn văn bản:\\n{context}\\n[|AI|] \", \"Không có thông tin cho câu hỏi của bạn.\\n[|Con người|]\"],\n",
    "    [\"Sử dụng đoạn trích sau đây để trả lời, nếu không có thông tin thì phản hồi không trả lời được.\\n{context}\\nCâu hỏi: {question}\\n[|AI|] \",\"Xin lỗi, tôi không có câu trả lời cho câu hỏi của bạn.\\n[|Con người|]\"],\n",
    "    [\"Hãy trả lời câu hỏi sau đây, nếu không có thông tin thì trả lời không trả lời được.\\nVăn bản:\\n{context}\\n{question}\\n[|AI|] \",\"Xin lỗi, tôi không trả lời được câu hỏi này.\\n[|Con người|]\"],\n",
    "]\n",
    "    \n",
    "no_answers = [\n",
    "    \"Xin lỗi, tôi không có thông tin cho câu hỏi của bạn.\\n[|Con người|]\",\n",
    "    \"Tôi không có câu trả lời cho câu hỏi này.\\n[|Con người|]\",\n",
    "    \"Xin lỗi bạn, tôi không có câu trả lời.\\n[|Con người|]\",\n",
    "    \"Không có câu trả lời cho câu hỏi của bạn.\\n[|Con người|]\",\n",
    "    \"Xin lỗi, tôi không thể trả lời câu hỏi này.\\n[|Con người|]\",\n",
    "]\n",
    "def mapper1(x):\n",
    "    return {\n",
    "        'input': (pre_text + choice(prompts1) + \"\\n[|AI|] \").format(question=x['question_translated'], context=x['context_translated']),\n",
    "        'output': choice(no_answers)\n",
    "    }\n",
    "\n",
    "def mapper2(x):\n",
    "    c = choice(prompts2)\n",
    "    return {\n",
    "        'input': (pre_text + c[0]).format(question=x['question_translated'], context=x['context_translated']),\n",
    "        'output': c[1]\n",
    "    }\n",
    "\n",
    "\n",
    "temp = squadv2.train_test_split(test_size=0.5, seed=42)\n",
    "final_1 = temp['train'].map(mapper1, remove_columns=squadv2.column_names)\n",
    "final_2 = temp['test'].map(mapper2, remove_columns=squadv2.column_names)\n",
    "print(final_1, final_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_1.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_2.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = concatenate_datasets([final_1, final_2])\n",
    "final.to_json('../../../data/training_21_8/squadv2_no_ans_2000_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-d0864ec1de14c06f/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-75e4a36a86b0b199/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "visquad_1 = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/translated/vi_squad/dev.json')\n",
    "visquad_2 = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/translated/vi_squad/test.json')\n",
    "\n",
    "def extract_context_question_answer(ds):\n",
    "    results = []\n",
    "    for i in ds[0]['data']:\n",
    "        for j in i['paragraphs']:\n",
    "            for k in j['qas']:\n",
    "                results.append({\n",
    "                    'context': j['context'],\n",
    "                    'question': k['question'],\n",
    "                    'answer': [a['text'] for a in k['answers']]\n",
    "                })\n",
    "    return Dataset.from_pandas(pd.DataFrame(results))\n",
    "\n",
    "temp1 = extract_context_question_answer(visquad_1)\n",
    "temp2 = extract_context_question_answer(visquad_2)\n",
    "visquad = concatenate_datasets([temp1, temp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de09187633de4e66b01130d485c3723d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9895384"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visquad.to_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/translated/vi_squad/vi_squad_test.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_start': 6,\n",
       "  'text': 'nằm ở điểm gặp nhau của các hành trình thương mại đường bộ và đường sông'},\n",
       " {'answer_start': 12,\n",
       "  'text': 'điểm gặp nhau của các hành trình thương mại đường bộ và đường sông, và là trung tâm của một vùng nông nghiệp giàu có'},\n",
       " {'answer_start': 12,\n",
       "  'text': 'điểm gặp nhau của các hành trình thương mại đường bộ và đường sông, và là trung tâm của một vùng nông nghiệp giàu có'},\n",
       " {'answer_start': 12,\n",
       "  'text': 'điểm gặp nhau của các hành trình thương mại đường bộ và đường sông, và là trung tâm của một vùng nông nghiệp giàu có'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visquad_1[0]['data'][0]['paragraphs'][0]['qas'][0]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visquad_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visquad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [\"văn hoá xã hội\", \"toán và khoa học\", \"sức khoẻ\", \"tư vấn và giáo dục\", \"máy tính và internet\", \"thể thao\", \"kinh doanh và kinh tế\", \"âm nhạc và giải trí\", \"gia đình và các mối quan hệ\", \"pháp luật\"]\n",
    "\n",
    "topic_map = {\n",
    "    str(k): v for k, v in zip(range(len(topic_names)), topic_names)\n",
    "}\n",
    "topic = Dataset.from_json('../../../data/translated/query_topic_translated.jsonl')\n",
    "topic_df = topic.to_pandas()\n",
    "topic_df = topic_df[topic_df['topic'].apply(lambda x: x != '9')]\n",
    "topic_df['topic_name'] = topic_df['topic'].apply(lambda x: topic_map[x])\n",
    "topic = Dataset.from_pandas(topic_df).select_columns(['topic_name', 'question_translated']).rename_column('question_translated', 'question').shuffle().select(range(3250))\n",
    "\n",
    "faqs = Dataset.from_json('../../../data/translated/all_faqs.json')\n",
    "def mapper(x):\n",
    "    i = x['input'].find('\\nĐiều luật liên quan: ')\n",
    "    return {\n",
    "        'question': x['input'][:i].removeprefix('Câu hỏi: '),\n",
    "        'topic_name': 'pháp luật'\n",
    "    }\n",
    "faqs = faqs.map(mapper, remove_columns=faqs.column_names)\n",
    "faqs = faqs.shuffle().select(range(750))\n",
    "\n",
    "topic = concatenate_datasets([topic, faqs]).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic.to_pandas()['topic_name'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "pretext = \"Cuộc trò chuyện giữa con người và trợ lý AI.\\n[|Con người|] \"\n",
    "type1_input_prompts = [\n",
    "    \"Cho biết câu hỏi sau thuộc chủ đề nào?\\n{question}\\n[|AI|] \",\n",
    "    \"Câu hỏi sau đây thuộc chủ đề nào?\\n{question}\\n[|AI|] \",\n",
    "    \"Sau đây là một câu hỏi, hãy cho biết nó thuộc chủ đề nào?\\nCâu hỏi: {question}\\n[|AI|] \",\n",
    "    \"\\nHỏi: {question}\\nCâu hỏi trên thuộc chủ đề nào?\\n[|AI|] \",\n",
    "    \"\\n{question}\\nChủ đề của câu hỏi trên là gì?\\n[|AI|] \",\n",
    "    \"Giúp tôi xác định chủ đề của câu hỏi sau:\\n{question}\\n[|AI|] \",\n",
    "]\n",
    "type1_output_prompts = [\n",
    "    \"Câu hỏi này thuộc chủ đề {topic_name}.\\n[|Con người|]\",\n",
    "    \"{topic_name}.\\n[|Con người|]\",\n",
    "    \"Chủ đề của câu hỏi này là {topic_name}.\\n[|Con người|]\",\n",
    "]    \n",
    "\n",
    "def type1_prompt(x):\n",
    "    return {\n",
    "        'input': (pretext + choice(type1_input_prompts)).format(question=x['question']),\n",
    "        'output': choice(type1_output_prompts).format(topic_name=x['topic_name'])\n",
    "    }\n",
    "\n",
    "type2_input_prompts = [\n",
    "    \"Câu hỏi sau đây có thuộc chủ đề {topic_name} không?\\nCâu hỏi: {question}\\n[|AI|] \",\n",
    "    \"Đây có phải là câu hỏi thuộc chủ đề {topic_name} không?\\n{question}\\n[|AI|] \",\n",
    "    \"Cho biết nếu câu hỏi sau đây thuộc chủ đề {topic_name}?\\n{question}\\n[|AI|] \",\n",
    "]\n",
    "type2_output_prompts = [\n",
    "    \"Đúng vậy, câu hỏi này thuộc chủ đề {topic_name}.\\n[|Con người|]\",\n",
    "    \"Chính xác.\\n[|Con người|]\",\n",
    "    \"Đúng vậy.\\n[|Con người|]\",\n",
    "]\n",
    "\n",
    "def type2_prompt(x):\n",
    "    return {\n",
    "        'input': (pretext + choice(type2_input_prompts)).format(question=x['question'], topic_name=x['topic_name']),\n",
    "        'output': choice(type2_output_prompts).format(topic_name=x['topic_name'])\n",
    "    }\n",
    "\n",
    "type3_input_prompts = [\n",
    "    \"Câu hỏi sau đây có thuộc chủ đề {other_topic_name} không?\\nHỏi: {question}\\n[|AI|] \",\n",
    "    \"Đây có phải là câu hỏi thuộc chủ đề {other_topic_name} không?\\n{question}\\n[|AI|] \",\n",
    "    \"Câu hỏi này có liên quan đến chủ đề {other_topic_name} không?\\nCâu hỏi: {question}\\n[|AI|] \",\n",
    "    \"Cho biết nếu câu hỏi sau đây thuộc chủ đề {other_topic_name}?\\n{question}\\n[|AI|] \",\n",
    "    \"{question}\\nCâu hỏi trên có liên quan đến chủ đề {other_topic_name} không?\\n[|AI|] \",\n",
    "]\n",
    "type3_output_prompts = [\n",
    "    \"Không, câu hỏi này không thuộc chủ đề {other_topic_name}.\\n[|Con người|]\",\n",
    "    \"Không đúng.\\n[|Con người|]\",\n",
    "    \"Không đúng, câu hỏi này thuộc chủ đề {topic_name}.\\n[|Con người|]\",\n",
    "    \"Chủ đề của câu hỏi này là {topic_name} chứ không phải {other_topic_name}.\\n[|Con người|]\",\n",
    "]\n",
    "\n",
    "def type3_prompt(x):\n",
    "    other = choice([topic for topic in topic_names if topic != x['topic_name']])\n",
    "    return {\n",
    "        'input': (pretext + choice(type3_input_prompts)).format(question=x['question'], other_topic_name=other),\n",
    "        'output': choice(type3_output_prompts).format(topic_name=x['topic_name'], other_topic_name=other)        \n",
    "    }\n",
    "\n",
    "temp = topic.train_test_split(test_size=2400, seed=42)\n",
    "type3_data = temp['train']\n",
    "temp = temp['test'].train_test_split(test_size=1200, seed=42)\n",
    "type1_data = temp['train']\n",
    "type2_data = temp['test']\n",
    "print(len(type1_data), len(type2_data), len(type3_data))\n",
    "\n",
    "final_type1 = type1_data.map(type1_prompt, remove_columns=topic.column_names)\n",
    "final_type2 = type2_data.map(type2_prompt, remove_columns=topic.column_names)\n",
    "final_type3 = type3_data.map(type3_prompt, remove_columns=topic.column_names)\n",
    "\n",
    "topic_classification = concatenate_datasets([final_type1, final_type2, final_type3]).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = topic_classification.shuffle()[0]\n",
    "print(a['input'] + a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_classification.to_json('../../../data/training_21_8/topic_classification_4000_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/training_21_8/'\n",
    "datasets = [\n",
    "    ['dolly_5k_samples.jsonl', 4000], # 5000\n",
    "    ['faqs_400_samples.jsonl', None], # 400\n",
    "    ['squadv2_no_ans_1500_samples.jsonl', 600], # 500\n",
    "    ['topic_classification_4000_samples.jsonl', 500], # 3000\n",
    "    ['query_gen_500_up_samples.jsonl', None], # 500\n",
    "    # ['code_related_ocapi_6k_samples.jsonl', None],\n",
    "    # ['gpt4_instruct_10k.jsonl', None],\n",
    "    # ['no_code_ocapi_30k_samples.jsonl', None],\n",
    "    # ['oasst_5k_samples.jsonl', None],\n",
    "    # ['orca_25k_samples.jsonl', None],\n",
    "    # ['quora_5k_samples.jsonl', None],\n",
    "    # ['wivi_30k_samples.jsonl', None],\n",
    "    # ['wizard_40k_samples.jsonl', None],\n",
    "]\n",
    "def clean(ds, max_tokens=2048):\n",
    "    def mapper(x):\n",
    "        for column in ds.column_names:\n",
    "            x[column] = x[column].replace('[|Human|]','[|Con người|]').replace('\\n[|Con người|]\\n[|Con người|]', '\\n[|Con người|]').replace('\\r\\n', '\\n')\n",
    "        return x\n",
    "    \n",
    "    def len_mapper(x):\n",
    "        input_len = len(tokenizer.tokenize(x['input']))\n",
    "        output_len = len(tokenizer.tokenize(x['output']))\n",
    "        return {\n",
    "            'input_len': input_len,\n",
    "            'output_len': output_len,\n",
    "            'len': input_len + output_len\n",
    "        }\n",
    "    def filter(x):\n",
    "        for column in ds.column_names:\n",
    "            if x[column] == '' or x[column] is None:\n",
    "                return False\n",
    "        if x['len'] > max_tokens:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    return ds.map(mapper,batched=False).map(len_mapper, batched=False).filter(filter)\n",
    "\n",
    "def load_datasets(dataset_size=None, max_tokens=2048):\n",
    "    data = []\n",
    "    for ds_config in datasets:\n",
    "        ds = Dataset.from_json(root_path + ds_config[0])\n",
    "        df = ds.to_pandas()\n",
    "        df['source'] = ds_config[0].split('.')[0].split('_')[0]\n",
    "        ds = Dataset.from_pandas(df)\n",
    "        if ds_config[1] is not None:\n",
    "            ds = ds.shuffle(seed=42).select(range(min(ds_config[1], len(ds))))\n",
    "        for check in ['input', 'output']:\n",
    "            if check not in ds.column_names:\n",
    "                raise ValueError(\"Dataset must have input, output columns\")\n",
    "        # take only the input and output columns\n",
    "        ds = ds.select_columns(['input', 'output'])\n",
    "        print(ds_config[0], ds)\n",
    "        data.append(ds)\n",
    "    ds = concatenate_datasets(data, axis=0)\n",
    "    if dataset_size is None: dataset_size = len(ds)\n",
    "    ds = ds.shuffle(seed=42).select(range(dataset_size))\n",
    "    return clean(ds, max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_datasets(max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_pandas()['output_len'].quantile(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = ds.shuffle().select(range(54000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = other.to_pandas()\n",
    "other_df[other_df['output_len'] <= 50].sample(1)['output'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = concatenate_datasets([important, other]).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pandas()['output_len'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_json('../../../data/training_21_8/60k_mixed_2.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pandas()['len'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds.filter(lambda x: x['len'] <= 1000)\n",
    "t = temp.shuffle()[0]\n",
    "print(t['input'] + t['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_pandas().hist(column='len', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shuffle().select(range(60000)).to_json('../../../data/training_21_8/mix_60k.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()\n",
    "df['len'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['output_len'] <= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[df['output_len'] <= 40].sample(1)\n",
    "print(temp['input'].values[0] + temp['output'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[df['len'] <= 2000].reset_index(drop=True)\n",
    "final_ds = Dataset.from_pandas(final_df).select_columns(['input', 'output'])\n",
    "final_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "final_df['len'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds.to_json('../../../data/training_21_8/all_21_8.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_oriented = final_ds.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructs = final_ds.shuffle().select(range(40000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = concatenate_datasets([task_oriented, instructs]).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_json('../../../data/training_21_8/final_51k_25_8_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pandas().hist(column='len', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final.shuffle()[0]\n",
    "print(temp['input'] + temp['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/training_21_8/all_21_8.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(x):\n",
    "    return {\n",
    "        'input_len': len(tokenizer.encode(x['input'])),\n",
    "        'output_len': len(tokenizer.encode(x['output']))\n",
    "    }\n",
    "\n",
    "ds = ds.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_pandas().hist(column='input_len', bins=50)\n",
    "ds.to_pandas().hist(column='output_len', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_pandas()['output_len'].quantile(0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/training_21_8/'\n",
    "dataset_configs = [\n",
    "    ['code_related_ocapi_6k_samples.jsonl', 'instruct'],\n",
    "    ['dolly_5k_samples.jsonl', 'instruct'],\n",
    "    ['faqs_400_samples.jsonl', 'instruct'],\n",
    "    ['gpt4_instruct_10k.jsonl', 'instruct'],\n",
    "    ['no_code_ocapi_30k_samples.jsonl', 'instruct'],\n",
    "    ['query_gen_500_up_samples.jsonl', 'instruct'],\n",
    "    ['orca_25k_samples.jsonl', 'instruct'],\n",
    "    ['role_play_5k_up_samples.jsonl', 'instruct'],\n",
    "    ['squadv2_no_ans_1500_samples.jsonl', 'instruct'],\n",
    "    ['topic_classification_4000_samples.jsonl', 'instruct'],\n",
    "    ['wizard_40k_samples.jsonl', 'instruct'],\n",
    "    ['wivi_30k_samples.jsonl', 'chat'],\n",
    "    ['quora_5k_samples.jsonl', 'chat'],\n",
    "    ['oasst_5k_samples.jsonl', 'chat'],\n",
    "]\n",
    "def len_analysis(dataset_configs):\n",
    "    def mapper(x):\n",
    "        return {\n",
    "            'input_len': len(tokenizer.encode(x['input'])),\n",
    "            'output_len': len(tokenizer.encode(x['output']))\n",
    "        }\n",
    "    collections = {}\n",
    "    for ds_config in dataset_configs:\n",
    "        name = ds_config[0].split('.')[0]\n",
    "        collections[name] = Dataset.from_json(root_path + ds_config[0])\n",
    "    for k, v in collections.items():\n",
    "        collections[k] = v.map(mapper, batched=False, remove_columns=v.column_names)\n",
    "    for k, v in collections.items():\n",
    "        print('Dataset: ', k)\n",
    "        df = v.to_pandas()\n",
    "        df['input_len'].hist(bins=50)\n",
    "        plt.show()\n",
    "        df['output_len'].hist(bins=50)\n",
    "        plt.show()\n",
    "        print('---------------------')\n",
    "\n",
    "len_analysis(dataset_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '/kaggle/input/general-chatbot-5-8/60k_mixed_2.jsonl'\n",
    "DATASET_FORMAT = 'input-output'\n",
    "OUTPUT_DIR = './outputs/'\n",
    "\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "LEARNING_RATE = '0.03'\n",
    "LR_SCHEDULER_TYPE = 'cosine'\n",
    "WARMUP_RATIO = 0.03\n",
    "\n",
    "LORA_R = 128\n",
    "LORA_ALPHA = 32 \n",
    "LORA_DROPOUT = 0.1\n",
    "\n",
    "TRAIN_ON_SOURCE = False\n",
    "SOURCE_MAX_LENGTH = 1024\n",
    "TARGET_MAX_LENGTH = 1024\n",
    "\n",
    "LOGGING_STEPS = 20\n",
    "SAVE_STEPS = 100\n",
    "SAVE_TOTAL_LIMIT = 4\n",
    "\n",
    "def check(args):\n",
    "    assert args.dataset == DATASET\n",
    "    assert args.dataset_format == DATASET_FORMAT\n",
    "    assert args.output_dir == OUTPUT_DIR\n",
    "    assert args.per_device_train_batch_size == PER_DEVICE_TRAIN_BATCH_SIZE\n",
    "    assert args.gradient_accumulation_steps == GRADIENT_ACCUMULATION_STEPS\n",
    "    assert args.learning_rate == LEARNING_RATE\n",
    "    assert args.lr_scheduler_type == LR_SCHEDULER_TYPE\n",
    "    assert args.warmup_ratio == WARMUP_RATIO\n",
    "    assert args.lora_r == LORA_R\n",
    "    assert args.lora_alpha == LORA_ALPHA\n",
    "    assert args.lora_dropout == LORA_DROPOUT\n",
    "    assert args.train_on_source == TRAIN_ON_SOURCE\n",
    "    assert args.source_max_length == SOURCE_MAX_LENGTH\n",
    "    assert args.target_max_length == TARGET_MAX_LENGTH\n",
    "    assert args.logging_steps == LOGGING_STEPS\n",
    "    assert args.save_steps == SAVE_STEPS\n",
    "    assert args.save_total_limit == SAVE_TOTAL_LIMIT\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
