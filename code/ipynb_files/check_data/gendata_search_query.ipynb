{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set()\n",
    "rcParams['figure.figsize'] = (20,10)\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings('ignore')\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, pipeline\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-c507d95be8d43b3a/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "oasst = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/oasst/en_oasst.json')\n",
    "def get_conversation(ds):\n",
    "    for temp0 in ds:\n",
    "        conv = temp0['text'].removeprefix('The conversation between human and AI assistant.\\n')\n",
    "        temp1 = conv.split('[|Human|]')[-1]\n",
    "        temp2 = temp1.split('[|AI|]')[0]\n",
    "        i = conv.find(temp2)\n",
    "        conv = conv[:i + len(temp2)]\n",
    "        yield conv\n",
    "    \n",
    "gen = get_conversation(oasst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Below is a history of the conversation so far, and a new question asked by the user that needs to be answered by searching in a general knowledge base.\n",
    "Generate a  search query based on the conversation and the new question. \n",
    "Do not include any text inside [] or <<>> in the search query terms.\n",
    "Do not include any special characters like '+'.\n",
    "Return only the query in json format: {\"query\": \"generated query\"}\n",
    "If you cannot generate a search query, return just the number 0.\n",
    "\n",
    "Conversation history:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-c507d95be8d43b3a/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "oasst = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/oasst/en_oasst.json')\n",
    "def create_dataset(ds):\n",
    "    result = []\n",
    "    for temp0 in ds.select(range(100)):\n",
    "        conv = temp0['text'].removeprefix('The conversation between human and AI assistant.\\n')\n",
    "        temp1 = conv.split('[|Human|]')[-1]\n",
    "        temp2 = temp1.split('[|AI|]')[0]\n",
    "        i = conv.find(temp2)\n",
    "        conv = conv[:i + len(temp2)]\n",
    "        result.append(conv)\n",
    "    \n",
    "    return Dataset.from_dict({'text': result})\n",
    "    \n",
    "dataset = create_dataset(oasst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667f0ea9da54cab97cd80a43f5f948e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "135980"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_json('../../../data/search_query.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = next(gen)\n",
    "prefix = \"\"\"Below is a history of the conversation so far, and a new question asked by the user that needs to be answered by searching in a general knowledge base.\n",
    "Generate a  search query based on the conversation and the new question. \n",
    "Do not include any text inside [] or <<>> in the search query terms.\n",
    "Do not include any special characters like '+'.\n",
    "Return only the query in json format: {\"query\": \"generated query\"}\n",
    "If you cannot generate a search query, return just the number 0.\n",
    "\n",
    "Conversation history:\n",
    "\"\"\"\n",
    "\n",
    "print(prefix + conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \\\n",
    "{\n",
    "\"query\": \"kid-friendly science projects without using chemicals or potentially harmful materials\"\n",
    "}\n",
    "\n",
    "\n",
    "def save_query(conversation, query):\n",
    "    with open('../../data/retrieve_query_gen_oasst.jsonl', 'a') as f:\n",
    "        js = {\n",
    "            'conversation': conversation,\n",
    "            'query': query,\n",
    "        }\n",
    "        f.write(json.dumps(js) + '\\n')\n",
    "\n",
    "save_query(conv, query['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3461,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-b66275377ff3550a/0.0.0)\n",
      "Loading cached processed dataset at /Users/phamhoang1408/.cache/huggingface/datasets/json/default-b66275377ff3550a/0.0.0/cache-184e20a9bb51ef67.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(465, 2)"
      ]
     },
     "execution_count": 3461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora = Dataset.from_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/quora_chat_data.json')\n",
    "def check(text):\n",
    "    for x in ['law', 'legal', 'lawyers']:\n",
    "        if x in text:\n",
    "            return True\n",
    "temp = quora.filter(lambda x: check(x['topic']))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a history of the conversation so far, and a new question asked by the user that needs to be answered by searching in a general knowledge base.\n",
      "Generate a  search query based on the conversation and the new question. \n",
      "Do not include any text inside [] or <<>> in the search query terms.\n",
      "Do not include any special characters like '+'.\n",
      "Return only the query in json format: {\"query\": \"generated query\"}\n",
      "If you cannot generate a search query, return just the number 0.\n",
      "\n",
      "Conversation history:\n",
      "[|Human|] I want to know the step by step guide to invest in share market in India.\n",
      "[|AI|] Sure, I can help with that. Firstly, you need to open a demat and trading account with a registered stockbroker.\n",
      "[|Human|] How do I find a registered stockbroker in India?\n",
      "[|AI|] You can visit the websites of National Stock Exchange (NSE) or Bombay Stock Exchange (BSE) to get a list of registered stockbrokers in India.\n",
      "[|Human|] What documents are required to open a demat and trading account?\n",
      "[|AI|] You will need to provide identity proof (PAN card), address proof, bank details and a passport size photograph to open a demat and trading account.\n",
      "[|Human|] How do I start trading once I have a demat and trading account?\n",
      "[|AI|] You can start trading by placing buy and sell orders for stocks through your stockbroker either online or offline.\n",
      "[|Human|] How do I track my investments?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv = next(gen)\n",
    "prefix = \"\"\"Below is a history of the conversation so far, and a new question asked by the user that needs to be answered by searching in a general knowledge base.\n",
    "Generate a  search query based on the conversation and the new question. \n",
    "Do not include any text inside [] or <<>> in the search query terms.\n",
    "Do not include any special characters like '+'.\n",
    "Return only the query in json format: {\"query\": \"generated query\"}\n",
    "If you cannot generate a search query, return just the number 0.\n",
    "\n",
    "Conversation history:\n",
    "\"\"\"\n",
    "\n",
    "print(prefix + conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(ds):\n",
    "    for temp0 in ds:\n",
    "        conv = temp0['input'].removeprefix('The conversation between human and AI assistant.\\n')\n",
    "        temp1 = conv.split('[|Human|]')[-2]\n",
    "        temp2 = temp1.split('[|AI|]')[0]\n",
    "        i = conv.find(temp2)\n",
    "        conv = conv[:i + len(temp2)]\n",
    "        yield conv\n",
    "gen = get_conversation(quora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 3463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversation between human and AI assistant.\n",
      "[|Human|] I was curious to know if there are any countries without private criminal lawyers.\n",
      "[|AI|] Yes, there are actually some countries where the government is responsible for providing legal representation for criminal defendants.\n",
      "[|Human|] Do you know the names of those countries?\n",
      "[|AI|] Yes, some examples include Japan, Norway, and Sweden.\n",
      "[|Human|] That's interesting. Do you know why those countries have this system?\n",
      "[|AI|] From what I understand, it's due to the belief that all citizens have the right to legal representation, regardless of their ability to pay for it. It's also a way to ensure a fair trial and prevent corruption in the legal system.\n",
      "[|Human|] I see. Are there any drawbacks to this system?\n",
      "[|AI|] One potential drawback is that the quality of legal representation may not be as high as it would be if defendants were able to hire their own lawyers. Additionally, the government may not have enough resources to provide adequate legal representation to all defendants.\n",
      "[|Human|] \n"
     ]
    }
   ],
   "source": [
    "print(temp.shuffle()[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3471,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \\\n",
    "{\"query\": \"How to track investments in share market India\"}\n",
    "\n",
    "def save_query(conversation, query):\n",
    "    with open('../../data/retrieve_query_gen_quora.jsonl', 'a') as f:\n",
    "        js = {\n",
    "            'conversation': conversation,\n",
    "            'query': query,\n",
    "        }\n",
    "        f.write(json.dumps(js) + '\\n')\n",
    "\n",
    "save_query(conv, query['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = pd.read_json('/Users/phamhoang1408/Desktop/Phase 2 Viettel/main_repo/data/original/share_gpt_no_code_conversations_40k.json', orient='records', lines=True)\n",
    "share.columns = ['input']\n",
    "share.dropna(inplace=True)\n",
    "share.reset_index(drop=True, inplace=True)\n",
    "share = Dataset.from_pandas(share)\n",
    "def check(text):\n",
    "    for x in ['law', 'legal', 'lawyers']:\n",
    "        if x in text:\n",
    "            return True\n",
    "temp = share.filter(lambda x: check(x['input']))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(share.shuffle()[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(ds):\n",
    "    for temp0 in ds:\n",
    "        conv = temp0['input'].removeprefix('The conversation between human and AI assistant.\\n')\n",
    "        temp1 = conv.split('[|Human|]')[-2]\n",
    "        temp2 = temp1.split('[|AI|]')[0]\n",
    "        i = conv.find(temp2)\n",
    "        conv = conv[:i + len(temp2)]\n",
    "        yield conv\n",
    "gen = get_conversation(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2023,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a history of the conversation so far, and a new question asked by the user that needs to be answered by searching in a general knowledge base.\n",
      "Generate a  search query based on the conversation and the new question. \n",
      "Do not include any text inside [] or <<>> in the search query terms.\n",
      "Do not include any special characters like '+'.\n",
      "Return only the query in json format: {\"query\": \"generated query\"}\n",
      "If you cannot generate a search query, return just the number 0.\n",
      "\n",
      "Conversation history:\n",
      "[|Human|] Please write a limerick based on Hegel's \"Phenomenology of Spirit\"\n",
      "[|AI|] There once was a philosopher named Hegel\n",
      "Whose work on the spirit was quite legal\n",
      "He wrote of our minds\n",
      "In his famous tome finds\n",
      "The journey towards self-consciousness is regal\n",
      "[|Human|] Please write a sonnet based on Kant's \"Critique of Pure Reason\"\n",
      "[|AI|] In Kant's \"Critique of Pure Reason\" we find\n",
      "A treatise on knowledge and its design\n",
      "He wrote of the mind\n",
      "And the concepts it does bind\n",
      "In order to grasp the world, truth to divine\n",
      "\n",
      "He spoke of the categories of thought\n",
      "And the principles on which they are brought\n",
      "To bear on the world we see\n",
      "And the understanding that must be\n",
      "If we are to make sense of all that we've sought\n",
      "\n",
      "But Kant also warned of the limits we face\n",
      "In our quest for knowledge and its place\n",
      "In the grand scheme of things\n",
      "He showed how our reasoning rings\n",
      "True only within certain bounds and its space\n",
      "\n",
      "So let us be mindful of what we can know\n",
      "And the limitations that our minds do show\n",
      "As we strive for the truth\n",
      "And seek to find our proof\n",
      "In the world and the mysteries that it holds.\n",
      "[|Human|] Please compose a summary of Heidegger's \"Being and Time\" in epic verse.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv = next(gen)\n",
    "prefix = \"\"\"Below is a history of the conversation so far, and a new question asked by the user that needs to be answered by searching in a general knowledge base.\n",
    "Generate a  search query based on the conversation and the new question. \n",
    "Do not include any text inside [] or <<>> in the search query terms.\n",
    "Do not include any special characters like '+'.\n",
    "Return only the query in json format: {\"query\": \"generated query\"}\n",
    "If you cannot generate a search query, return just the number 0.\n",
    "\n",
    "Conversation history:\n",
    "\"\"\"\n",
    "\n",
    "print(prefix + conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \\\n",
    "{\"query\": \"Media criticism of RESTRICT Act covering end-users, targeted nature of the bill according to Senator Warner\"}\n",
    "\n",
    "def save_query(conversation, query):\n",
    "    with open('../../data/retrieve_query_gen_sharegpt.jsonl', 'a') as f:\n",
    "        js = {\n",
    "            'conversation': conversation,\n",
    "            'query': query,\n",
    "        }\n",
    "        f.write(json.dumps(js) + '\\n')\n",
    "\n",
    "save_query(conv, query['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
