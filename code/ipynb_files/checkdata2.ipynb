{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set()\n",
    "rcParams['figure.figsize'] = (20,10)\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings('ignore')\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, pipeline\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN_DAILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Dataset.from_json('../../data/translated/cnn_dailymail_30k_samples_len_100_1200_words_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template=\"Tóm tắt ngắn gọn đoạn văn bản sau đây:\\n{article_translated}\\nĐoạn văn bản đã được tóm tắt:\\n\"\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': input_template.format(article_translated=x['article_translated']),\n",
    "        'output': x['highlights_translated']\n",
    "    }\n",
    "\n",
    "temp_cnn = cnn.shuffle().select(range(15000)).map(mapper,batched=False, remove_columns=['article_translated','highlights_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_cnn[0]['input'] + temp_cnn[0]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = temp_cnn.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['input'] + x['output']))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length.to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cnn.to_json('../../data/training_2_8/cnn_15k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cnn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIALOG SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = Dataset.from_json('../../data/translated/dialogsum_10k_samples_len_50_words_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template=\"Tóm tắt ngắn gọn đoạn hội thoại sau đây:\\n{dialogue_translated}\\nĐoạn hội thoại đã được tóm tắt:\\n\"\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': input_template.format(dialogue_translated=x['dialogue_translated']),\n",
    "        'output': x['summary_translated']\n",
    "    }\n",
    "\n",
    "temp_dialog = dialog.shuffle().select(range(10000)).map(mapper,batched=False, remove_columns=['dialogue_translated','summary_translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dialog.to_json('../../data/training_2_8/dialogsum_10k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = Dataset.from_json('../../data/training_31_7/faq_chat_10k.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['input'].removeprefix(text),\n",
    "    }\n",
    "\n",
    "temp_faqs = faqs.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_faqs.to_json('../../data/training_2_8/faqs.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARE_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = Dataset.from_json('../../data/translated/share_gpt_no_code_conversations_40k_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = share.filter(lambda x: len(tokenizer.tokenize(x[\"input\"])) < 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(share.shuffle()[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['input']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share[0]['output'].removeprefix('Cuộc trò chuyện giữa con người và trợ lý AI.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['output'].removeprefix(text),\n",
    "    }\n",
    "\n",
    "share = share.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share.to_json('../../data/training_2_8/share_gpt_2k_tokens.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora = Dataset.from_json('../../data/translated/quora_chat_data_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quora.shuffle()[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['prompt']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_quora = quora.shuffle().select(range(15000))\n",
    "temp_quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['prompt'].removeprefix(text),\n",
    "    }\n",
    "\n",
    "temp_quora = temp_quora.map(mapper, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_quora.to_json('../../data/training_2_8/quora_15k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OASST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_oasst = Dataset.from_json('../../data/translated/en_oasst_translated.json')\n",
    "en_oasst = en_oasst.rename_column('text_translated','text')\n",
    "vi_oasst = Dataset.from_json('../../data/original/oasst/vi_oasst.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasst = concatenate_datasets([en_oasst,vi_oasst],axis=0)\n",
    "oasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['text'].removeprefix(text),\n",
    "    }\n",
    "\n",
    "temp_oasst = oasst.map(mapper, batched=False, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_oasst.to_json('../../data/training_2_8/oasst_21k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasst.shuffle().select(range(1000)).map(lambda x: {'len':len(tokenizer.tokenize(x['text']))}).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALPACA CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = Dataset.from_json('../../data/training_31_7/alpaca_chat_15k.jsonl')\n",
    "alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Cuộc trò chuyện giữa con người và trợ lý AI.\\n'\n",
    "def mapper(x):\n",
    "    return {\n",
    "        'input': text,\n",
    "        'output': x['input'].removeprefix(text),\n",
    "    }\n",
    "\n",
    "temp_alpaca = alpaca.map(mapper, batched=False, remove_columns=['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_alpaca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_alpaca.to_json('../../data/training_2_8/alpaca_chat_15k_samples.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 INSTRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-3973f66dcdf3ca58/0.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction_translated', 'input_translated', 'response_translated'],\n",
       "    num_rows: 17873\n",
       "})"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4 = Dataset.from_json('../../data/translated/gpt4_instruct_similarity_0_9_translated.json')\n",
    "gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b233d7ea009c4dff8eb891e049f1e3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template1 = \"Dưới đây là mô tả về một yêu cầu, kèm theo một đầu vào cho yêu cầu đó. Hãy đưa ra câu trả lời phù hợp với yêu cầu.\\nYêu cầu:\\n{instruction_translated}\\nĐầu vào:\\n{input_translated}\\nCầu trả lời:\\n\"\n",
    "template2 = \"Dưới đây là mô tả về một yêu cầu. Hãy đưa ra câu trả lời phù hợp với yêu cầu.\\nYêu cầu:\\n{instruction_translated}\\nCầu trả lời:\\n\"\n",
    "\n",
    "def mapper(x):\n",
    "    if x['input_translated'] != '' and x['input_translated'] is not None:\n",
    "        template = template1.format(\n",
    "            instruction_translated=x['instruction_translated'], \n",
    "            input_translated=x['input_translated']\n",
    "        )\n",
    "    else:\n",
    "        template = template2.format(instruction_translated=x['instruction_translated'])\n",
    "    return {\n",
    "        'input': template,\n",
    "        'output': x['response_translated']\n",
    "    }\n",
    "\n",
    "temp_gpt4 = gpt4.map(mapper,batched=False, remove_columns=gpt4.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output'],\n",
       "    num_rows: 17873\n",
       "})"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dưới đây là mô tả về một yêu cầu, kèm theo một đầu vào cho yêu cầu đó. Hãy đưa ra câu trả lời phù hợp với yêu cầu.\n",
      "Yêu cầu:\n",
      "Dựa trên thông tin đã cho, đề xuất mẫu xe tốt nhất cho khách hàng.\n",
      "Đầu vào:\n",
      "Hồ sơ khách hàng: Gia đình 4 người, đi làm 15 dặm hàng ngày, có ý thức bảo vệ môi trường, thích xe hơi tiết kiệm nhiên liệu và có ngân sách $35.000.\n",
      "Cầu trả lời:\n",
      "Xem xét quy mô gia đình, việc đi lại hàng ngày, các mối quan tâm về môi trường, ưu tiên tiết kiệm nhiên liệu và ngân sách, tôi muốn giới thiệu một chiếc xe hybrid chẳng hạn như Toyota Prius. Mẫu xe này mang lại sự cân bằng giữa hiệu suất nhiên liệu, khả năng chi trả và không gian cho một gia đình bốn người.\n"
     ]
    }
   ],
   "source": [
    "a = temp_gpt4.shuffle()[0]\n",
    "print(a['input']+a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2047b9c4bc54bd4a92b617426f2241d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "29405688"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_gpt4.to_json('../../data/training_2_8/gpt4_instruct.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "def load_dataset(folder_path, dataset_size=None):\n",
    "    data = []\n",
    "    for path in glob(folder_path + \"/*.jsonl\"):\n",
    "        ds = Dataset.from_json(path)\n",
    "        for check in ['input', 'output']:\n",
    "            if check not in ds.column_names:\n",
    "                raise ValueError(\"Dataset must have input, output columns\")\n",
    "        # take only the input and output columns\n",
    "        ds = ds.select_columns(['input', 'output'])\n",
    "        data.append(ds)\n",
    "    if dataset_size is None:\n",
    "        return concatenate_datasets(data, axis=0).shuffle(seed=42)\n",
    "    return (\n",
    "        concatenate_datasets(data, axis=0).shuffle(seed=42).select(range(dataset_size))\n",
    "    )\n",
    "\n",
    "def clean(ds):\n",
    "    def mapper(x):\n",
    "        for column in ds.column_names:\n",
    "            x[column] = x[column].replace('[|Human|]','[|Con người|]')\n",
    "        return x\n",
    "    def filter(x):\n",
    "        for column in ds.column_names:\n",
    "            if x[column] == '' or x[column] is None:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    new_ds = ds.map(mapper,batched=False)\n",
    "    new_ds = new_ds.filter(filter)\n",
    "    return new_ds        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-f98428edfa869424/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-ed1c46715fa633b6/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-8f6ba5c753f41139/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-81f50c62a3dafb9a/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-4dcf8fe6e0bf3db6/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-3479b7e1d603347c/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-27e07d763f4a0b21/0.0.0)\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-4e1805ae55f877e8/0.0.0)\n",
      "Loading cached shuffled indices for dataset at /Users/phamhoang1408/.cache/huggingface/datasets/json/default-f98428edfa869424/0.0.0/cache-ac4a201a4c8ed2ad.arrow\n",
      "Loading cached processed dataset at /Users/phamhoang1408/.cache/huggingface/datasets/json/default-f98428edfa869424/0.0.0/cache-f56c9ba939f1c143.arrow\n",
      "Loading cached processed dataset at /Users/phamhoang1408/.cache/huggingface/datasets/json/default-f98428edfa869424/0.0.0/cache-64b21ee652408f2a.arrow\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('../../data/training_2_8')\n",
    "ds = clean(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuộc trò chuyện giữa con người và trợ lý AI.\n",
      "[|Con người|] Điều gì xảy ra nếu tôi giữ một tờ giấy theo chiều ngang bằng hai tay và tôi buông một tay?\n",
      "[|AI|] Nếu bạn giữ một tờ giấy theo chiều ngang bằng hai tay và buông một tay ra, tờ giấy sẽ bắt đầu nghiêng về phía tay buông. Mức độ nghiêng phụ thuộc vào góc mà tờ giấy được giữ và lực tác dụng của tay còn lại.\n",
      "\n",
      "Nếu giấy được giữ ở một góc tương đối bằng phẳng, nó có thể giữ nguyên trong một thời gian ngắn trước khi trọng lực chiếm ưu thế và giấy bắt đầu nghiêng. Khi nó nghiêng, sự phân bổ trọng lượng của giấy sẽ thay đổi, khiến nó ngày càng trở nên không ổn định. Nếu góc nghiêng đủ dốc, tờ giấy cuối cùng sẽ rơi xuống đất.\n",
      "\n",
      "Trong một số trường hợp, bạn có thể nhanh chóng lấy tờ giấy bằng tay kia để ngăn tờ giấy rơi xuống. Tuy nhiên, điều này phụ thuộc vào tốc độ phản ứng của bạn và khoảng cách của tay kia với tờ giấy.\n",
      "\n",
      "Nhìn chung, kết quả của việc buông một tay khi đang giữ một tờ giấy theo chiều ngang sẽ phụ thuộc vào một số yếu tố, chẳng hạn như góc của tờ giấy, lực do tay còn lại tác dụng và thời gian phản ứng của bạn.\n",
      "[|Con người|] Sẽ mất bao lâu để tờ giấy rơi xuống sàn giả sử tờ giấy là một mảnh A4?\n",
      "[|AI|] Thời gian để tờ giấy rơi xuống sàn có thể khác nhau tùy thuộc vào một số yếu tố, bao gồm góc tờ giấy được thả, mức độ gió nơi tờ giấy được thả xuống và tờ giấy cách mặt đất bao xa. Nếu tờ giấy được giữ ở độ cao ngang ngực trong phòng ít gió, tờ giấy sẽ chạm đất sau 1-5 giây.\n",
      "[|Con người|] Bạn có thể sử dụng các phương trình lực cản không khí cũng như thời gian để nó rơi trong chân không, với điều kiện là nó được giữ ở độ cao trung bình ngang ngực, để xác định xem tờ giấy sẽ mất bao lâu để chạm đất như một hàm của góc của nó? Để đơn giản, giả sử tờ giấy cứng và sẽ không xoay hoặc lật xung quanh, nhưng có thể rơi ở bất kỳ góc độ nào, từ ngang sang dọc.\n"
     ]
    }
   ],
   "source": [
    "a = ds.shuffle()[0]\n",
    "print(a['input'] + a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a67a8e6f2d7424c9b7fb28de2b6ceed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "521947314"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.to_json('../../data/training_2_8/all_2_8.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Tóm tắt ngắn gọn đoạn hội thoại sau đây:\\n[|Con người|] Chào buổi tối, thưa ông. Tôi có thể làm gì cho bạn?\\n[|AI|] Bourbon, làm ơn.\\n[|Con người|] Bạn muốn rượu Bourbon của mình như thế nào, uống thẳng hay uống trên đá?\\n[|AI|] Cho nước đá vào nhé.\\n[|Con người|] Đây thưa ngài. Bourbon với nước đá.\\n[|AI|] Cảm ơn bạn. Bây giờ tôi nợ bạn bao nhiêu?\\n[|Con người|] Rượu bourbon là 15 đô la cộng với 10 % phí dịch vụ. Vậy tổng cộng là 16. 5 đô la.\\n[|AI|] Không sao đâu. Đây là 20 đô la và bạn có thể giữ tiền lẻ.\\n[|Con người|] Cảm ơn rất nhiều.\\nĐoạn hội thoại đã được tóm tắt:\\n',\n",
       " 'output': '[|AI|] đặt hàng Bourbon với nước đá và thanh toán với sự hỗ trợ của [|Con người|].'}"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shuffle()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
