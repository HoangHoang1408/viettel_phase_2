{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "prompt = \"\"\"Cuộc trò chuyện giữa con người và trợ lý AI.\n",
    "[|Con người|] Trả lời câu hỏi sau đây bằng cách lựa chọn 1 trong 4 đáp án A, B, C, D và không đưa ra giải thích thêm.\n",
    "{question}\n",
    "{choices}\n",
    "Đáp án:\n",
    "[|AI|] \"\"\"\n",
    "\n",
    "\n",
    "def load_arc(path):\n",
    "    def mapper(x):\n",
    "        choices = [x[t] for t in ['option_a', 'option_b', 'option_c', 'option_d']]\n",
    "        return {\n",
    "            'input': prompt.format(question=x['instruction'], choices='\\n'.join(f'{i}. {c}' for i, c in zip(['A', 'B', 'C', 'D'], choices))),\n",
    "            'ref': x['answer'],\n",
    "            'category': x['id'].split('/')[-1].split('_')[0],\n",
    "        }\n",
    "    ds = Dataset.from_json(path)\n",
    "    ds = ds.map(mapper, remove_columns=ds.column_names, num_proc=4)\n",
    "    return ds\n",
    "\n",
    "def load_mmlu(path):\n",
    "    def mapper(x):\n",
    "        choices = [x[t] for t in ['option_a', 'option_b', 'option_c', 'option_d']]\n",
    "        return {\n",
    "            'input': prompt.format(question=x['instruction'], choices='\\n'.join(f'{i}. {c}' for i, c in zip(['A', 'B', 'C', 'D'], choices))),\n",
    "            'ref': x['answer'],\n",
    "            'category': x['id'].split('/')[0],\n",
    "        }\n",
    "    ds = Dataset.from_json(path)\n",
    "    ds = ds.map(mapper, remove_columns=ds.column_names, num_proc=4)\n",
    "    return ds\n",
    "\n",
    "# ds format: {'input': prompt_str, 'ref': str[A, B, C, D], 'category': str}\n",
    "temp = [\n",
    "    {\n",
    "        'name': 'ARC',\n",
    "        'path': 'data/ARC-V1-Feb2018-2/ARC-Challenge/ARC-Challenge-Train.jsonl',\n",
    "        'load_func': load_arc,\n",
    "    },\n",
    "    {\n",
    "        'name': 'MMLU',\n",
    "        'path': 'data/MMLU/MMLU.jsonl',\n",
    "        'load_func': load_mmlu,\n",
    "    }\n",
    "]\n",
    "\n",
    "def report(generate_func, ds_path_name_load=temp): # generate_func: input -> pred\n",
    "    def mapper(x):\n",
    "        return {\n",
    "            'input': x['input'],\n",
    "            'ref': x['ref'],\n",
    "            'pred': generate_func(x['input']),\n",
    "            'category': x['category'],\n",
    "        }\n",
    "    \n",
    "    def report_for_category(ds):\n",
    "        res = {\n",
    "            x: {'ref': [], 'pred': []} for x in ds.unique('category')\n",
    "        }\n",
    "        for row in ds:\n",
    "            res[row['category']]['ref'].append(row['ref'])\n",
    "            res[row['category']]['pred'].append(row['pred'])\n",
    "        for x in res:\n",
    "            res[x]['acc'] = sum(1 for i, j in zip(res[x]['ref'], res[x]['pred']) if i == j) / len(res[x]['ref'])\n",
    "        return res\n",
    "    \n",
    "    datasets = {\n",
    "        x['name']: x['load_func'](x['path']).map(mapper) for x in ds_path_name_load\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        x: report_for_category(datasets[x]) for x in datasets\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if prompt is string or not\n",
    "prompt = \"hello\"\n",
    "print(isinstance(prompt, str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompts):\n",
    "    try:\n",
    "        res = chatbot.inferencer.generate(prompt)\n",
    "        index = res.find('[|AI|]')\n",
    "        if index == -1:\n",
    "            raise Exception('No answer found')\n",
    "    except:\n",
    "        \n",
    "    return res[index + 7:index +8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-f63ca446b2d21b89/0.0.0)\n",
      "Loading cached processed dataset at /Users/phamhoang1408/.cache/huggingface/datasets/json/default-f63ca446b2d21b89/0.0.0/cache-27108160d296fd3b_*_of_00004.arrow\n",
      "Found cached dataset json (/Users/phamhoang1408/.cache/huggingface/datasets/json/default-b67d9addebc8e93d/0.0.0)\n",
      "Loading cached processed dataset at /Users/phamhoang1408/.cache/huggingface/datasets/json/default-b67d9addebc8e93d/0.0.0/cache-1d94efbccab2c05c_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "arc = load_arc('../../data/translated/arc/arc_all.json')\n",
    "mmlu = load_mmlu('../../data/translated/mmlu/mmlu_all.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
